{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kjNxUX51Lh0k"
   },
   "outputs": [],
   "source": [
    "#@title Imports\n",
    "# %reset -f \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "from itertools import product as cartesian_prod\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn import cluster\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Keep this commented for generating python file\n",
    "\n",
    "# import os\n",
    "# num_layers = [4]\n",
    "# betas = [3]\n",
    "# num_neurons = [20,50,100,200,500,1000]\n",
    "\n",
    "# lrs =[0.001, 0.0001]\n",
    "\n",
    "# for num_layer in num_layers:\n",
    "#     for num_neuron in num_neurons:\n",
    "#         for beta in betas:\n",
    "#             for lr in lrs:\n",
    "#                 args = \"\"\n",
    "#                 args += \" --numlayer \"+str(num_layer)\n",
    "#                 args += \" --numnodes \"+str(num_neuron)\n",
    "#                 args += \" --beta \"+str(beta)\n",
    "#                 args += \" --lr \"+str(lr)\n",
    "#                 command = \"python Decision_tree_DLGN_expts.py \"+args\n",
    "#                 print(\"=======::::::::=========:::::::::::============\")\n",
    "#                 print(command)\n",
    "#                 os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.numlayer=4\n",
    "        self.numnodes=50\n",
    "        self.beta=3.\n",
    "        self.lr=0.001        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4_50_3_1.0e-03\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "args =  Args()\n",
    "\n",
    "num_layer = args.numlayer\n",
    "num_neuron = args.numnodes\n",
    "beta = args.beta\n",
    "lr=args.lr\n",
    "\n",
    "saved_epochs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,18,20,22,24,26,28,30,32,64,128,256,512,1024,2048, \n",
    "                4096, 8192, 16384, 32768]\n",
    "filename_suffix = str(num_layer)\n",
    "filename_suffix += \"_\"+str(num_neuron)\n",
    "filename_suffix += \"_\"+str(int(beta))\n",
    "filename_suffix += \"_\"+format(lr,\".1e\")\n",
    "print(filename_suffix)\n",
    "\n",
    "\n",
    "no_of_batches=10 \n",
    "weight_decay=0.0\n",
    "num_hidden_nodes=[num_neuron]*num_layer\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDx4xoSOFzR2"
   },
   "source": [
    "**Variable parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2iXNxcu4L6kT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20438695839260426 0.22399764837846275 0.1406952694770958\n",
      "0.20035261763198306 -0.10880821902702326 0.529858066522114\n"
     ]
    }
   ],
   "source": [
    "#@title Synthetic data\n",
    "def set_npseed(seed):\n",
    "\tnp.random.seed(seed)\n",
    "\n",
    "\n",
    "def set_torchseed(seed):\n",
    "\ttorch.manual_seed(seed)\n",
    "\ttorch.cuda.manual_seed(seed)\n",
    "\ttorch.cuda.manual_seed_all(seed)\n",
    "\ttorch.backends.cudnn.deterministic = True\n",
    "\ttorch.backends.cudnn.benchmark = False\n",
    "\n",
    "#Four mode classification data\n",
    "\n",
    "\n",
    "def data_gen_decision_tree(num_data=1000, dim=2, seed=0, w_list=None, b_list=None, \n",
    "\t\t\t\t\t\t\tvals=None, num_levels=2):\n",
    "\t'''\n",
    "\tConstruct a complete decision tree with 2**num_levels-1 internal nodes, \n",
    "\te.g. num_levels=2 means there are 3 internal nodes.\n",
    "\tw_list, b_list is a list of size equal to num_internal_nodes, ie. weight and bias for each node \n",
    "\tvals is a list of size equal to num_leaf_nodes, with values +1 or -1, ie. output of each leaf node\n",
    "\t'''\n",
    "\t# np.random.seed(6790)\n",
    "\tset_npseed(seed=seed)\n",
    "\tnum_internal_nodes = 2**num_levels - 1\n",
    "\tnum_leaf_nodes = 2**num_levels\n",
    "\tstats = np.zeros(num_internal_nodes+num_leaf_nodes)\n",
    "\n",
    "\tif vals is None:\n",
    "\t\tvals = np.arange(0,num_internal_nodes+num_leaf_nodes,1,dtype=np.int32)%2\n",
    "\t\tvals[:num_internal_nodes] = -99\n",
    "\n",
    "\tif w_list is None:\n",
    "\t\tw_list = np.random.standard_normal((num_internal_nodes, dim))\n",
    "\t\tw_list = w_list/np.linalg.norm(w_list, axis=1)[:, None]\n",
    "\t\tb_list = np.zeros((num_internal_nodes))\n",
    "\n",
    "\tdata_x = np.random.random_sample((num_data, dim))*2 - 1.\n",
    "\trelevant_stats = data_x @ w_list.T + b_list\n",
    "\t\n",
    "\tprint(relevant_stats[0,0], relevant_stats[0,1], relevant_stats[0,2])\n",
    "\tcurr_index = np.zeros(shape=(num_data), dtype=int)\n",
    "\t\n",
    "\tfor level in range(num_levels):\n",
    "\t\tnodes_curr_level=list(range(2**level - 1,2**(level+1)-1  ))\n",
    "\t\tfor el in nodes_curr_level:\n",
    "\t\t\tb_list[el]=-1*np.median(relevant_stats[curr_index==el,el])\n",
    "\t\t\trelevant_stats[:,el] += b_list[el]\n",
    "\t\tdecision_variable = np.choose(curr_index, relevant_stats.T) \n",
    "\t\t# Go down and right if wx+b>0 down and left otherwise. \n",
    "\t\t# i.e. 0 -> 1 if w[0]x+b[0]<0 and 0->2 otherwise\n",
    "\t\tcurr_index = (curr_index+1)*2 - (1-(decision_variable > 0))\n",
    "\n",
    "\tbound_dist = np.min(np.abs(relevant_stats), axis=1)\n",
    "\tthres = 0\n",
    "\tprint(relevant_stats[0,0], relevant_stats[0,1], relevant_stats[0,2])\n",
    "\tlabels = vals[curr_index]\n",
    "\tdata_x_pruned = data_x[bound_dist>thres]\n",
    "\tlabels_pruned = labels[bound_dist>thres]\n",
    "\trelevant_stats = np.sign(data_x_pruned @ w_list.T + b_list)\n",
    "\tnodes_active = np.zeros((len(data_x_pruned),  num_internal_nodes+num_leaf_nodes), dtype=np.int32)\n",
    "\tfor node in range(num_internal_nodes+num_leaf_nodes):\n",
    "\t\tif node==0:\n",
    "\t\t\tstats[node]=len(relevant_stats)\n",
    "\t\t\tnodes_active[:,0]=1\n",
    "\t\t\tcontinue\n",
    "\t\tparent = (node-1)//2\n",
    "\t\tnodes_active[:,node]=nodes_active[:,parent]\n",
    "\t\tright_child = node-(parent*2)-1 # 0 means left, 1 means right 1 has children 3,4\n",
    "\t\tif right_child==1:\n",
    "\t\t\tnodes_active[:,node] *= relevant_stats[:,parent]>0\n",
    "\t\tif right_child==0:\n",
    "\t\t\tnodes_active[:,node] *= relevant_stats[:,parent]<0\t\t\n",
    "\t\tstats = nodes_active.sum(axis=0)\n",
    "\treturn ((data_x_pruned, labels_pruned), (w_list, b_list, vals), stats)\n",
    "\n",
    "\n",
    "# w_list = np.array([[1., 0], [0, 1], [0, 1]])\n",
    "# b_list = np.array([0, 0.25, -0.25])\n",
    "# vals = np.array([-99, -99, -99, 0, 1, 1, 0])\n",
    "num_data = 12000\n",
    "input_dim= 2\n",
    "# seeds = np.random.randint(0,10000,5)\n",
    "seeds=[1387]\n",
    "# seeds = [2318]\n",
    "for seed in seeds:\n",
    "\t((data_x, labels), (w_list, b_list, vals), stats) = data_gen_decision_tree(\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tdim=input_dim, seed=seed, num_levels=4,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tnum_data=num_data)\n",
    "\tseed_set=seed\n",
    "w_list_old = np.array(w_list)\n",
    "b_list_old = np.array(b_list)\n",
    "\n",
    "num_data = len(data_x)\n",
    "num_train= num_data//2\n",
    "num_vali = num_data//4\n",
    "num_test = num_data//4\n",
    "train_data = data_x[:num_train,:]\n",
    "train_data_labels = labels[:num_train]\n",
    "\n",
    "vali_data = data_x[num_train:num_train+num_vali,:]\n",
    "vali_data_labels = labels[num_train:num_train+num_vali]\n",
    "\n",
    "test_data = data_x[num_train+num_vali :,:]\n",
    "test_data_labels = labels[num_train+num_vali :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.44, -0.9 ]),\n",
       " array([-0.35, -0.4 ]),\n",
       " -0.004034340760621202,\n",
       " 0.20438695839260426,\n",
       " 12000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_list[0],data_x[0],b_list[0],(w_list[0]@data_x[0]),num_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(data_x, labels, w_list, b_list, vals):\n",
    "    freq = np.zeros(len(vals))\n",
    "    for i, x in enumerate(data_x):\n",
    "        current_index = 1\n",
    "        while current_index < 16:\n",
    "            output = w_list[current_index-1]@x + b_list[current_index-1]\n",
    "            current_index *= 2\n",
    "            if output >= 0:\n",
    "                current_index += 1\n",
    "        if vals[current_index-1] == 1 and labels[i] != 1:\n",
    "            return False\n",
    "        if vals[current_index-1] == -1 and labels[i] != 0:\n",
    "            return False\n",
    "        if labels[i] == 0:\n",
    "            freq[current_index-1]-=1\n",
    "        else:\n",
    "            freq[current_index-1]+=1\n",
    "    return True, freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " array([   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,  750., -750.,  750.,\n",
       "        -750.,  750., -750.,  750., -750.,  750., -750.,  750., -750.,\n",
       "         750., -750.,  750., -750.]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check(data_x, labels, w_list, b_list, vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DLGN_FC(nn.Module):\n",
    "\tdef __init__(self, input_dim=None, output_dim=None, num_hidden_nodes=[], beta=30, mode='pwc'):\t\t\n",
    "\t\tsuper(DLGN_FC, self).__init__()\n",
    "\t\tself.num_hidden_layers = len(num_hidden_nodes)\n",
    "\t\tself.beta=beta  # Soft gating parameter\n",
    "\t\tself.mode = mode\n",
    "\t\tself.num_nodes=[input_dim]+num_hidden_nodes+[output_dim]\n",
    "\t\tself.gating_layers=nn.ModuleList()\n",
    "\t\tself.value_layers=nn.ModuleList()\n",
    "\t\t\n",
    "\t\tfor i in range(self.num_hidden_layers+1):\n",
    "\t\t\tif i!=self.num_hidden_layers:\n",
    "\t\t\t\ttemp = nn.Linear(self.num_nodes[i], self.num_nodes[i+1])\n",
    "\t\t\t\t# a = temp.weight.detach() \n",
    "\t\t\t\t# a /= a.norm(dim=1, keepdim=True)\n",
    "\t\t\t\tself.gating_layers.append(temp)\n",
    "\t\t\ttemp = nn.Linear(self.num_nodes[i], self.num_nodes[i+1], bias=False)\n",
    "\t\t\t# a = temp.weight.detach()\n",
    "\t\t\t# a /= a.norm(dim=1, keepdim=True)\n",
    "\t\t\tself.value_layers.append(temp)\n",
    "\n",
    "\n",
    "\tdef set_parameters_with_mask(self, to_copy, parameter_masks):\n",
    "\t\t# self and to_copy are DLGN_FC objects with same architecture\n",
    "\t\t# parameter_masks is compatible with dict(to_copy.named_parameters())\n",
    "\t\tfor (name, copy_param) in to_copy.named_parameters():\n",
    "\t\t\tcopy_param = copy_param.clone().detach()\n",
    "\t\t\torig_param  = self.state_dict()[name]\n",
    "\t\t\tif name in parameter_masks:\n",
    "\t\t\t\tparam_mask = parameter_masks[name]>0\n",
    "\t\t\t\torig_param[param_mask] = copy_param[param_mask]\n",
    "\t\t\telse:\n",
    "\t\t\t\torig_param = copy_param.data.detach()\n",
    "\t\n",
    "\n",
    "\t\t\t\t\t\t\t\t\n",
    "\n",
    "\tdef return_gating_functions(self):\n",
    "\t\teffective_weights = []\n",
    "\t\teffective_biases =[]\n",
    "\t\tfor i in range(self.num_hidden_layers):\n",
    "\t\t\tcurr_weight = self.gating_layers[i].weight.detach()\n",
    "\t\t\tcurr_bias = self.gating_layers[i].bias.detach()\n",
    "\t\t\tif i==0:\n",
    "\t\t\t\teffective_weights.append(curr_weight)\n",
    "\t\t\t\teffective_biases.append(curr_bias)\n",
    "\t\t\telse:\n",
    "\t\t\t\teffective_biases.append(torch.matmul(curr_weight,effective_biases[-1])+curr_bias)\n",
    "\t\t\t\teffective_weights.append(torch.matmul(curr_weight,effective_weights[-1]))\n",
    "\t\treturn effective_weights, effective_biases\n",
    "\t\t# effective_weights (and effective biases) is a list of size num_hidden_layers\n",
    "\t\t\t\t\t\t\t\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tgate_scores=[x]\n",
    "\n",
    "\t\tfor el in self.parameters():\n",
    "\t\t\tif el.is_cuda:\n",
    "\t\t\t\tdevice = torch.device('cuda')\n",
    "\t\t\telse:\n",
    "\t\t\t\tdevice = torch.device('cpu')\n",
    "\t\tif self.mode=='pwc':\n",
    "\t\t\tvalues=[torch.ones(x.shape).to(device)]\n",
    "\t\telse:\n",
    "\t\t\tvalues=[x]\n",
    "\t\t\n",
    "\t\tfor i in range(self.num_hidden_layers):\n",
    "\t\t\tgate_scores.append(self.gating_layers[i](gate_scores[-1]))\n",
    "\t\t\tcurr_gate_on_off = torch.sigmoid(self.beta * gate_scores[-1])\n",
    "\t\t\tvalues.append(self.value_layers[i](values[-1])*curr_gate_on_off)\n",
    "\t\tvalues.append(self.value_layers[self.num_hidden_layers](values[-1]))\n",
    "\t\t# Values is a list of size 1+num_hidden_layers+1\n",
    "\t\t#gate_scores is a list of size 1+num_hidden_layers\n",
    "\t\treturn values,gate_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Ncr5k6koMbD_"
   },
   "outputs": [],
   "source": [
    "#@title Train DLGN model\n",
    "def train_dlgn (DLGN_obj, train_data_curr,vali_data_curr,test_data_curr,\n",
    "\t\t\t\ttrain_labels_curr,test_labels_curr,vali_labels_curr,num_epoch=1,\n",
    "\t\t\t\tparameter_mask=dict()):\n",
    "\t\n",
    "\tdevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\tDLGN_obj.to(device)\n",
    "\n",
    "\tcriterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\toptimizer = optim.Adam(DLGN_obj.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "\n",
    "\ttrain_data_torch = torch.Tensor(train_data_curr)\n",
    "\tvali_data_torch = torch.Tensor(vali_data_curr)\n",
    "\ttest_data_torch = torch.Tensor(test_data_curr)\n",
    "\n",
    "\ttrain_labels_torch = torch.tensor(train_labels_curr, dtype=torch.int64)\n",
    "\ttest_labels_torch = torch.tensor(test_labels_curr, dtype=torch.int64)\n",
    "\tvali_labels_torch = torch.tensor(vali_labels_curr, dtype=torch.int64)\n",
    "\n",
    "\tnum_batches = no_of_batches\n",
    "\tbatch_size = len(train_data_curr)//num_batches\n",
    "\tlosses=[]\n",
    "\tDLGN_obj_store = []\n",
    "\tbest_vali_error = len(vali_labels_curr)\n",
    "\t\n",
    "\n",
    "\t# print(\"H3\")\n",
    "\t# print(DLGN_params)\n",
    "\ttrain_losses = []\n",
    "\trunning_loss = 0.7*num_batches # initial random loss = 0.7 \n",
    "\tfor epoch in tqdm(range(saved_epochs[-1])):  # loop over the dataset multiple times\n",
    "\t\tif epoch in saved_epochs:\n",
    "\t\t\tDLGN_obj_copy = deepcopy(DLGN_obj)\n",
    "\t\t\tDLGN_obj_copy.to(torch.device('cpu'))\n",
    "\t\t\tDLGN_obj_store.append(DLGN_obj_copy)\n",
    "\t\t\ttrain_losses.append(running_loss/num_batches)\n",
    "\t\t\tif running_loss/num_batches < 1e-5:\n",
    "\t\t\t\tbreak\n",
    "\t\trunning_loss = 0.0\n",
    "\t\tfor batch_start in range(0,len(train_data_curr),batch_size):\n",
    "\t\t\tif (batch_start+batch_size)>len(train_data_curr):\n",
    "\t\t\t\tbreak\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\tinputs = train_data_torch[batch_start:batch_start+batch_size]\n",
    "\t\t\ttargets = train_labels_torch[batch_start:batch_start+batch_size].reshape(batch_size)\n",
    "\t\t\tinputs = inputs.to(device)\n",
    "\t\t\ttargets = targets.to(device)\n",
    "\t\t\tvalues,gate_scores = DLGN_obj(inputs)\n",
    "\t\t\toutputs = torch.cat((-1*values[-1], values[-1]), dim=1)\n",
    "\t\t\tloss = criterion(outputs, targets)\t\t\t\n",
    "\t\t\tloss.backward()\n",
    "\t\t\tfor name,param in DLGN_obj.named_parameters():\n",
    "\t\t\t\tparameter_mask[name] = parameter_mask[name].to(device)\n",
    "\t\t\t\tparam.grad *= parameter_mask[name]   \n",
    "\t\t\toptimizer.step()\n",
    "\t\t\trunning_loss += loss.item()    \n",
    "\t\tlosses.append(running_loss/num_batches)\n",
    "\t\tinputs = vali_data_torch.to(device)\n",
    "\t\ttargets = vali_labels_torch.to(device)\n",
    "\t\tvalues,gate_scores =DLGN_obj(inputs)\n",
    "\t\tvali_preds = torch.cat((-1*values[-1], values[-1]), dim=1)\n",
    "\t\tvali_preds = torch.argmax(vali_preds, dim=1)\n",
    "\t\tvali_error= torch.sum(targets!=vali_preds)\n",
    "\t\tif vali_error < best_vali_error:\n",
    "\t\t\tDLGN_obj_return = deepcopy(DLGN_obj)\n",
    "\t\t\tbest_vali_error = vali_error\n",
    "\tplt.figure()\n",
    "\tplt.title(\"DLGN loss vs epoch\")\n",
    "\tplt.plot(losses)\n",
    "\tif not os.path.exists('figures'):\n",
    "\t\tos.mkdir('figures')\n",
    "\n",
    "\tfilename = 'figures/'+filename_suffix +'.pdf'\n",
    "\tplt.savefig(filename)\n",
    "\tDLGN_obj_return.to(torch.device('cpu'))\n",
    "\tdevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\treturn train_losses, DLGN_obj_return, DLGN_obj_store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PpN8Yby7Fllw"
   },
   "source": [
    "**Training a DLGN model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368
    },
    "id": "LF7PO4Lc2jzV",
    "outputId": "5858b9a2-48bb-4fdb-9d55-f37981c6f839"
   },
   "outputs": [],
   "source": [
    "set_torchseed(6675)\n",
    "# set_torchseed(5449)\n",
    "DLGN_init= DLGN_FC(input_dim=input_dim, output_dim=1, num_hidden_nodes=num_hidden_nodes, beta=beta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2154/32768 [16:11<3:50:02,  2.22it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/sooraj/sem/ugrc/benchmarks/DecisionTree_DLGN_Shared_Aug8.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sooraj/sem/ugrc/benchmarks/DecisionTree_DLGN_Shared_Aug8.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     train_parameter_masks[name]\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sooraj/sem/ugrc/benchmarks/DecisionTree_DLGN_Shared_Aug8.ipynb#X21sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m set_torchseed(\u001b[39m5000\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/sooraj/sem/ugrc/benchmarks/DecisionTree_DLGN_Shared_Aug8.ipynb#X21sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m train_losses, DLGN_obj_final, DLGN_obj_store \u001b[39m=\u001b[39m train_dlgn(train_data_curr\u001b[39m=\u001b[39;49mtrain_data,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sooraj/sem/ugrc/benchmarks/DecisionTree_DLGN_Shared_Aug8.ipynb#X21sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                                             vali_data_curr\u001b[39m=\u001b[39;49mvali_data,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sooraj/sem/ugrc/benchmarks/DecisionTree_DLGN_Shared_Aug8.ipynb#X21sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                                             test_data_curr\u001b[39m=\u001b[39;49mtest_data,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sooraj/sem/ugrc/benchmarks/DecisionTree_DLGN_Shared_Aug8.ipynb#X21sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m                                             train_labels_curr\u001b[39m=\u001b[39;49mtrain_data_labels,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sooraj/sem/ugrc/benchmarks/DecisionTree_DLGN_Shared_Aug8.ipynb#X21sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m                                             vali_labels_curr\u001b[39m=\u001b[39;49mvali_data_labels,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sooraj/sem/ugrc/benchmarks/DecisionTree_DLGN_Shared_Aug8.ipynb#X21sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m                                             test_labels_curr\u001b[39m=\u001b[39;49mtest_data_labels,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sooraj/sem/ugrc/benchmarks/DecisionTree_DLGN_Shared_Aug8.ipynb#X21sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m                                             DLGN_obj\u001b[39m=\u001b[39;49mdeepcopy(DLGN_init),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sooraj/sem/ugrc/benchmarks/DecisionTree_DLGN_Shared_Aug8.ipynb#X21sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m                                             parameter_mask\u001b[39m=\u001b[39;49mtrain_parameter_masks)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sooraj/sem/ugrc/benchmarks/DecisionTree_DLGN_Shared_Aug8.ipynb#X21sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mempty_cache() \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sooraj/sem/ugrc/benchmarks/DecisionTree_DLGN_Shared_Aug8.ipynb#X21sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# print(DLGN_obj_store[-1].beta)\u001b[39;00m\n",
      "\u001b[1;32m/home/sooraj/sem/ugrc/benchmarks/DecisionTree_DLGN_Shared_Aug8.ipynb Cell 16\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sooraj/sem/ugrc/benchmarks/DecisionTree_DLGN_Shared_Aug8.ipynb#X21sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sooraj/sem/ugrc/benchmarks/DecisionTree_DLGN_Shared_Aug8.ipynb#X21sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m targets \u001b[39m=\u001b[39m targets\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/sooraj/sem/ugrc/benchmarks/DecisionTree_DLGN_Shared_Aug8.ipynb#X21sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m values,gate_scores \u001b[39m=\u001b[39m DLGN_obj(inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sooraj/sem/ugrc/benchmarks/DecisionTree_DLGN_Shared_Aug8.ipynb#X21sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\u001b[39m*\u001b[39mvalues[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], values[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sooraj/sem/ugrc/benchmarks/DecisionTree_DLGN_Shared_Aug8.ipynb#X21sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, targets)\t\t\t\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/sooraj/sem/ugrc/benchmarks/DecisionTree_DLGN_Shared_Aug8.ipynb Cell 16\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sooraj/sem/ugrc/benchmarks/DecisionTree_DLGN_Shared_Aug8.ipynb#X21sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m \tgate_scores\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgating_layers[i](gate_scores[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sooraj/sem/ugrc/benchmarks/DecisionTree_DLGN_Shared_Aug8.ipynb#X21sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m \tcurr_gate_on_off \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msigmoid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbeta \u001b[39m*\u001b[39m gate_scores[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/sooraj/sem/ugrc/benchmarks/DecisionTree_DLGN_Shared_Aug8.ipynb#X21sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m \tvalues\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalue_layers[i](values[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\u001b[39m*\u001b[39mcurr_gate_on_off)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sooraj/sem/ugrc/benchmarks/DecisionTree_DLGN_Shared_Aug8.ipynb#X21sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m values\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalue_layers[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_hidden_layers](values[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sooraj/sem/ugrc/benchmarks/DecisionTree_DLGN_Shared_Aug8.ipynb#X21sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m \u001b[39m# Values is a list of size 1+num_hidden_layers+1\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sooraj/sem/ugrc/benchmarks/DecisionTree_DLGN_Shared_Aug8.ipynb#X21sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m \u001b[39m#gate_scores is a list of size 1+num_hidden_layers\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_parameter_masks=dict()\n",
    "for name,parameter in DLGN_init.named_parameters():\n",
    "    if name[:5]==\"value_\"[:5]:\n",
    "        train_parameter_masks[name]=torch.ones_like(parameter) # Updating all value network layers\n",
    "    if name[:5]==\"gating_\"[:5]:\n",
    "        train_parameter_masks[name]=torch.ones_like(parameter)\n",
    "    train_parameter_masks[name].to(device)\n",
    "\n",
    "set_torchseed(5000)\n",
    "train_losses, DLGN_obj_final, DLGN_obj_store = train_dlgn(train_data_curr=train_data,\n",
    "                                            vali_data_curr=vali_data,\n",
    "                                            test_data_curr=test_data,\n",
    "                                            train_labels_curr=train_data_labels,\n",
    "                                            vali_labels_curr=vali_data_labels,\n",
    "                                            test_labels_curr=test_data_labels,\n",
    "                                            DLGN_obj=deepcopy(DLGN_init),\n",
    "                                            parameter_mask=train_parameter_masks)\n",
    "torch.cuda.empty_cache() \n",
    "\n",
    "# print(DLGN_obj_store[-1].beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DLGN_obj_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/sooraj/sem/ugrc/benchmarks/DecisionTree_DLGN_Shared_Aug8.ipynb Cell 17\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sooraj/sem/ugrc/benchmarks/DecisionTree_DLGN_Shared_Aug8.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# print(len(DLGN_obj_store))\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sooraj/sem/ugrc/benchmarks/DecisionTree_DLGN_Shared_Aug8.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# print(\"Hi\")\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sooraj/sem/ugrc/benchmarks/DecisionTree_DLGN_Shared_Aug8.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/sooraj/sem/ugrc/benchmarks/DecisionTree_DLGN_Shared_Aug8.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m train_outputs_values, train_outputs_gate_scores \u001b[39m=\u001b[39mDLGN_obj_final(torch\u001b[39m.\u001b[39mTensor(train_data)\u001b[39m.\u001b[39mto(device))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sooraj/sem/ugrc/benchmarks/DecisionTree_DLGN_Shared_Aug8.ipynb#X22sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m train_preds \u001b[39m=\u001b[39m train_outputs_values[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sooraj/sem/ugrc/benchmarks/DecisionTree_DLGN_Shared_Aug8.ipynb#X22sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DLGN_obj_final' is not defined"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('outputs'):\n",
    "    os.mkdir('outputs')\n",
    "# print(len(DLGN_obj_store))\n",
    "# print(\"Hi\")\n",
    "device=torch.device('cpu')\n",
    "train_outputs_values, train_outputs_gate_scores =DLGN_obj_final(torch.Tensor(train_data).to(device))\n",
    "train_preds = train_outputs_values[-1]\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "outputs = torch.cat((-1*train_preds,train_preds), dim=1)\n",
    "targets = torch.tensor(train_data_labels, dtype=torch.int64)\n",
    "train_loss = criterion(outputs, targets)\n",
    "train_preds = train_preds.detach().numpy()\n",
    "filename = 'outputs/'+filename_suffix+'.txt'\n",
    "original_stdout = sys.stdout\n",
    "with open(filename,'w') as f:\n",
    "    sys.stdout = f\n",
    "    print(\"Setup:\")\n",
    "    print(\"Num neurons : \", DLGN_obj_final.num_nodes)\n",
    "    print(\" Beta :\", DLGN_obj_final.beta)\n",
    "    print(\" lr :\", lr)\n",
    "    print(\"=======================\")\n",
    "    print(train_losses)\n",
    "    print(\"==========Best validated model=============\")\n",
    "    print(\"Train error=\",np.sum(train_data_labels != (np.sign(train_preds[:,0])+1)//2 ))\n",
    "    print(\"Train loss = \", train_loss)\n",
    "    print(\"Num_train_data=\",len(train_data_labels))\n",
    "    sys.stdout = original_stdout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_outputs_values, test_outputs_gate_scores =DLGN_obj_final(torch.Tensor(test_data))\n",
    "test_preds = test_outputs_values[-1]\n",
    "test_preds = test_preds.detach().numpy()\n",
    "filename = 'outputs/'+filename_suffix+'.txt'\n",
    "original_stdout = sys.stdout\n",
    "with open(filename,'a') as f:\n",
    "    sys.stdout = f\n",
    "    print(\"Test error=\",np.sum(test_data_labels != (np.sign(test_preds[:,0])+1)//2 ))\n",
    "    print(\"Num_test_data=\",len(test_data_labels))\n",
    "    sys.stdout = original_stdout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learned feature statistics of best validation model\n",
    "\n",
    "w_list = np.concatenate((w_list_old,-w_list_old),axis=0)\n",
    "\n",
    "effective_weights, effective_biases = DLGN_obj_store[0].return_gating_functions()\n",
    "wts_list_init=[]\n",
    "for layer in range(0,len(effective_weights)):\n",
    "    wts =  np.array(effective_weights[layer].data.detach().numpy())\n",
    "    wts /= np.linalg.norm(wts, axis=1)[:,None]\n",
    "    wts_list_init.append(wts)\n",
    "wts_list_init = np.concatenate(wts_list_init)\n",
    "\n",
    "\n",
    "effective_weights, effective_biases = DLGN_obj_final.return_gating_functions()\n",
    "\n",
    "wts_list=[]\n",
    "for layer in range(len(effective_weights)):\n",
    "    wts =  np.array(effective_weights[layer].data.detach().numpy())\n",
    "    wts /= np.linalg.norm(wts, axis=1)[:,None]\n",
    "    wts_list.append(wts)\n",
    "wts_list = np.concatenate(wts_list)\n",
    "\n",
    "pd0 =  pairwise_distances(w_list,wts_list_init)\n",
    "pd1 =  pairwise_distances(w_list,wts_list)\n",
    "\n",
    "\n",
    "filename = 'outputs/'+filename_suffix+'.txt'\n",
    "original_stdout = sys.stdout\n",
    "with open(filename,'a') as f:\n",
    "    sys.stdout = f\n",
    "    print(\"Shape of decision tree node hyperplanes \", w_list.shape)\n",
    "    print(\"Shape of all halfspace directions of DLGN\", wts_list.shape)\n",
    "    print(\"Distance of closest init DLGN halfspace to each labelling func hyperplane \\n\", pd0.min(axis=1)[:len(w_list_old)])\n",
    "    print(pd0.min(axis=1)[len(w_list_old):])\n",
    "    print(\"Distance of closest lrnd DLGN halfspace to each labelling func hyperplane \\n\", pd1.min(axis=1)[:len(w_list_old)])\n",
    "    print(pd1.min(axis=1)[len(w_list_old):])\n",
    "    print(\"Number of halfspaces within distance 0.8 of the Dtree hyperplanes \\n\", np.sum(pd1<0.8, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd1<0.8, axis=1)[len(w_list_old):])\n",
    "    print(\"Number of halfspaces within distance 0.6 of the Dtree hyperplanes \\n\", np.sum(pd1<0.6, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd1<0.6, axis=1)[len(w_list_old):])\n",
    "    print(\"Number of halfspaces within distance 0.4 of the Dtree hyperplanes \\n\", np.sum(pd1<0.4, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd1<0.4, axis=1)[len(w_list_old):])\n",
    "    print(\"Number of halfspaces within distance 0.3 of the Dtree hyperplanes \\n\", np.sum(pd1<0.3, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd1<0.3, axis=1)[len(w_list_old):])\n",
    "    print(\"Number of halfspaces within distance 0.2 of the Dtree hyperplanes \\n\", np.sum(pd1<0.2, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd1<0.2, axis=1)[len(w_list_old):])\n",
    "    print(\"Number of halfspaces within distance 0.1 of the Dtree hyperplanes \\n\", np.sum(pd1<0.1, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd1<0.1, axis=1)[len(w_list_old):])\n",
    "    print(\"=========================================\")\n",
    "    sys.stdout = original_stdout\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learned feature statistics of init model\n",
    "epoch_index=0\n",
    "effective_weights, effective_biases = DLGN_obj_store[epoch_index].return_gating_functions()\n",
    "wts_list=[]\n",
    "for layer in range(len(effective_weights)):\n",
    "    wts =  np.array(effective_weights[layer].data.detach().numpy())\n",
    "    wts /= np.linalg.norm(wts, axis=1)[:,None]\n",
    "    wts_list.append(wts)\n",
    "wts_list = np.concatenate(wts_list)\n",
    "pd0 =  pairwise_distances(w_list,wts_list_init)\n",
    "pd1 =  pairwise_distances(w_list,wts_list)\n",
    "pd_w_list = pairwise_distances(w_list, w_list)\n",
    "\n",
    "\n",
    "filename = 'outputs/'+filename_suffix+'.txt'\n",
    "original_stdout = sys.stdout\n",
    "with open(filename,'a') as f:\n",
    "    sys.stdout = f\n",
    "    print(\"===================================\")\n",
    "    print(\"Initial epoch\")\n",
    "    print(epoch_index)\n",
    "    print(\"===================================\")\n",
    "    train_outputs_values, train_outputs_gate_scores =DLGN_obj_store[epoch_index](torch.Tensor(train_data).to(device))\n",
    "    train_preds = train_outputs_values[-1]\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    outputs = torch.cat((-1*train_preds,train_preds), dim=1)\n",
    "    targets = torch.tensor(train_data_labels, dtype=torch.int64)\n",
    "    train_loss = criterion(outputs, targets)\n",
    "    train_preds = train_preds.detach().numpy()\n",
    "    test_outputs_values, test_outputs_gate_scores =DLGN_obj_store[epoch_index](torch.Tensor(test_data))\n",
    "    test_preds = test_outputs_values[-1]\n",
    "    test_preds = test_preds.detach().numpy()\n",
    "    print(\"Train error=\",np.sum(train_data_labels != (np.sign(train_preds[:,0])+1)//2 ))\n",
    "    print(\"Num_train_data=\",len(train_data_labels))\n",
    "    print(\"Train loss=\",train_loss.detach())\n",
    "    print(\"Test error=\",np.sum(test_data_labels != (np.sign(test_preds[:,0])+1)//2 ))\n",
    "    print(\"Num_test_data=\",len(test_data_labels))\n",
    "    print(\"===================================\")\n",
    "    print(\"Shape of decision tree node hyperplanes \", w_list.shape)\n",
    "    print(\"Shape of all halfspace directions of DLGN\", wts_list.shape)\n",
    "    print(\"Distance of closest init DLGN halfspace to each labelling func hyperplane \\n\", pd0.min(axis=1)[:len(w_list_old)])\n",
    "    print(pd0.min(axis=1)[len(w_list_old):])\n",
    "    print(\"Distance of closest lrnd DLGN halfspace to each labelling func hyperplane \\n\", pd1.min(axis=1)[:len(w_list_old)])\n",
    "    print(pd1.min(axis=1)[len(w_list_old):])\n",
    "    print(\"Number of halfspaces within distance 0.8 of the Dtree hyperplanes \\n\", np.sum(pd1<0.8, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd1<0.8, axis=1)[len(w_list_old):])\n",
    "    print(\"Number of halfspaces within distance 0.6 of the Dtree hyperplanes \\n\", np.sum(pd1<0.6, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd1<0.6, axis=1)[len(w_list_old):])\n",
    "    print(\"Number of halfspaces within distance 0.4 of the Dtree hyperplanes \\n\", np.sum(pd1<0.4, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd1<0.4, axis=1)[len(w_list_old):])\n",
    "    print(\"Number of halfspaces within distance 0.3 of the Dtree hyperplanes \\n\", np.sum(pd1<0.3, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd1<0.3, axis=1)[len(w_list_old):])\n",
    "    print(\"Number of halfspaces within distance 0.2 of the Dtree hyperplanes \\n\", np.sum(pd1<0.2, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd1<0.2, axis=1)[len(w_list_old):])\n",
    "    print(\"Number of halfspaces within distance 0.1 of the Dtree hyperplanes \\n\", np.sum(pd1<0.1, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd1<0.1, axis=1)[len(w_list_old):])\n",
    "    print(\"=========================================\")\n",
    "    sys.stdout = original_stdout    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learned feature statistics of last iteration model\n",
    "epoch_index=len(DLGN_obj_store)-1\n",
    "effective_weights, effective_biases = DLGN_obj_store[epoch_index].return_gating_functions()\n",
    "wts_list=[]\n",
    "for layer in range(len(effective_weights)):\n",
    "    wts =  np.array(effective_weights[layer].data.detach().numpy())\n",
    "    wts /= np.linalg.norm(wts, axis=1)[:,None]\n",
    "    wts_list.append(wts)\n",
    "wts_list = np.concatenate(wts_list)\n",
    "\n",
    "pd0 =  pairwise_distances(w_list,wts_list_init)\n",
    "pd1 =  pairwise_distances(w_list,wts_list)\n",
    "pd_w_list = pairwise_distances(w_list, w_list)\n",
    "w_list_random = np.random.standard_normal(w_list.shape)\n",
    "w_list_random /= np.linalg.norm(w_list_random, axis=1)[:,None]\n",
    "\n",
    "pd4 = pairwise_distances(w_list_random,wts_list)\n",
    "\n",
    "\n",
    "filename = 'outputs/'+filename_suffix+'.txt'\n",
    "original_stdout = sys.stdout\n",
    "with open(filename,'a') as f:\n",
    "    sys.stdout = f\n",
    "    print(\"===================================\")\n",
    "    print(\"last epoch: Training loss = \", train_losses[-1])\n",
    "    print(epoch_index)\n",
    "    print(saved_epochs[epoch_index])\n",
    "    print(\"===================================\")\n",
    "    train_outputs_values, train_outputs_gate_scores =DLGN_obj_store[epoch_index](torch.Tensor(train_data).to(device))\n",
    "    train_preds = train_outputs_values[-1]\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    outputs = torch.cat((-1*train_preds,train_preds), dim=1)\n",
    "    targets = torch.tensor(train_data_labels, dtype=torch.int64)\n",
    "    train_loss = criterion(outputs, targets)\n",
    "    train_preds = train_preds.detach().numpy()\n",
    "    test_outputs_values, test_outputs_gate_scores =DLGN_obj_store[epoch_index](torch.Tensor(test_data))\n",
    "    test_preds = test_outputs_values[-1]\n",
    "    test_preds = test_preds.detach().numpy()\n",
    "    print(\"Train error=\",np.sum(train_data_labels != (np.sign(train_preds[:,0])+1)//2 ))\n",
    "    print(\"Num_train_data=\",len(train_data_labels))\n",
    "    print(\"Train loss=\",train_loss.detach())\n",
    "    print(\"Test error=\",np.sum(test_data_labels != (np.sign(test_preds[:,0])+1)//2 ))\n",
    "    print(\"Num_test_data=\",len(test_data_labels))\n",
    "    print(\"===================================\")\n",
    "\n",
    "    print(\"Shape of decision tree node hyperplanes \", w_list.shape)\n",
    "    print(\"Shape of all halfspace directions of DLGN\", wts_list.shape)\n",
    "    print(\"Distance of closest init DLGN halfspace to each labelling func hyperplane \\n\", pd0.min(axis=1)[:len(w_list_old)])\n",
    "    print(pd0.min(axis=1)[len(w_list_old):])\n",
    "    print(\"Distance of closest lrnd DLGN halfspace to each labelling func hyperplane \\n\", pd1.min(axis=1)[:len(w_list_old)])\n",
    "    print(pd1.min(axis=1)[len(w_list_old):])\n",
    "    print(\"Number of halfspaces within distance 0.8 of the Dtree hyperplanes \\n\", np.sum(pd1<0.8, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd1<0.8, axis=1)[len(w_list_old):])\n",
    "    print(\"Number of halfspaces within distance 0.6 of the Dtree hyperplanes \\n\", np.sum(pd1<0.6, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd1<0.6, axis=1)[len(w_list_old):])\n",
    "    print(\"Number of halfspaces within distance 0.4 of the Dtree hyperplanes \\n\", np.sum(pd1<0.4, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd1<0.4, axis=1)[len(w_list_old):])\n",
    "    print(\"Number of halfspaces within distance 0.3 of the Dtree hyperplanes \\n\", np.sum(pd1<0.3, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd1<0.3, axis=1)[len(w_list_old):])\n",
    "    print(\"Number of halfspaces within distance 0.2 of the Dtree hyperplanes \\n\", np.sum(pd1<0.2, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd1<0.2, axis=1)[len(w_list_old):])\n",
    "    print(\"Number of halfspaces within distance 0.1 of the Dtree hyperplanes \\n\", np.sum(pd1<0.1, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd1<0.1, axis=1)[len(w_list_old):])\n",
    "\n",
    "\n",
    "    print(\"=========================================\")\n",
    "    print(\"No. of halfspaces within distance 0.8 of a random Dtree hyperplanes \\n\", np.sum(pd4<0.8, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd4<0.8, axis=1)[len(w_list_old):])\n",
    "    print(\"No. of halfspaces within distance 0.6 of a random Dtree hyperplanes \\n\", np.sum(pd4<0.6, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd4<0.6, axis=1)[len(w_list_old):])\n",
    "    print(\"No. of halfspaces within distance 0.4 of a random Dtree hyperplanes \\n\", np.sum(pd4<0.4, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd4<0.4, axis=1)[len(w_list_old):])\n",
    "    print(\"No. of halfspaces within distance 0.3 of a random Dtree hyperplanes \\n\", np.sum(pd4<0.3, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd4<0.3, axis=1)[len(w_list_old):])\n",
    "    print(\"No. of halfspaces within distance 0.2 of a random Dtree hyperplanes \\n\", np.sum(pd4<0.2, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd4<0.2, axis=1)[len(w_list_old):])\n",
    "    print(\"No. of halfspaces within distance 0.1 of a random Dtree hyperplanes \\n\", np.sum(pd4<0.1, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd4<0.1, axis=1)[len(w_list_old):])\n",
    "    sys.stdout = original_stdout    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_utils import train, test\n",
    "from network import Net \n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(input_dim=input_dim, output_dim=2, hidden_dim=1, num_layer=12, num_back_layer=0, dense=True, drop_type='none', net_type='locally_constant', approx='interpolation').to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, nesterov=True)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def get_train_loader(train_data, train_data_labels, batch_size):\n",
    "    # Convert data and labels to PyTorch tensors\n",
    "    train_data_tensor = torch.tensor(train_data, dtype=torch.float32)\n",
    "    train_data_labels_tensor = torch.tensor(train_data_labels, dtype=torch.long)\n",
    "\n",
    "    # Create a TensorDataset from the data and labels tensors\n",
    "    dataset = TensorDataset(train_data_tensor, train_data_labels_tensor)\n",
    "\n",
    "    # Create a DataLoader from the dataset\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return loader\n",
    "train_loader = get_train_loader(train_data, train_data_labels, batch_size=32)\n",
    "valid_loader = get_train_loader(vali_data, vali_data_labels, batch_size=32)\n",
    "test_loader = get_train_loader(test_data, test_data_labels, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sooraj/.local/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "/home/sooraj/.local/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6404758293952889 0.6348924412867575 0.6404060717867713 0.6628503750493486 0.640507324865819 0.6418145956607495\n",
      "0.6215182013217104 0.6564041839352674 0.6155418384889346 0.6695617844453218 0.6301979020737567 0.6437869822485207\n",
      "0.6128739742266254 0.6425893033353068 0.6097546589501611 0.6383734701934465 0.6280679375462278 0.6173570019723866\n",
      "0.6014920478980406 0.7067298204065522 0.5964545170120981 0.697986577181208 0.6218695418604262 0.6788954635108482\n",
      "0.5628133397942726 0.7053483323465561 0.569871442100534 0.6999605211212001 0.5744818002749712 0.6915187376725839\n",
      "0.5148591342140801 0.7661338069863824 0.5276341379935968 0.757994472956968 0.5391215563290688 0.749112426035503\n",
      "0.5095542418737959 0.7341622261693309 0.5232734977610723 0.7228582708251086 0.5299800428883329 0.7187376725838265\n",
      "0.5148359600411192 0.7280442076179199 0.5064123314075493 0.7453612317410185 0.5299085042415521 0.7207100591715976\n",
      "0.4977390818372854 0.761791987369252 0.5069636616177866 0.7540465850769839 0.5219535026324571 0.7400394477317555\n",
      "0.5122596049228786 0.7475823958950069 0.5242555187570216 0.738255033557047 0.5357418839042709 0.7191321499013806\n"
     ]
    }
   ],
   "source": [
    "best_score = 100000\n",
    "for epoch in range(0, 10):\n",
    "        scheduler.step(epoch)\n",
    "\n",
    "        train_approximate_loss = train(model, device, train_loader, optimizer, epoch, 'none',1)\n",
    "        # used for plotting learning curves\n",
    "        train_loss, train_score = test(model, device, train_loader, 'train')\n",
    "        valid_loss, valid_score = test(model, device, valid_loader, 'valid')\n",
    "        test_loss, test_score = test(model, device, test_loader, 'test')\n",
    "        \n",
    "        # early stopping version\n",
    "        if valid_score > best_score:\n",
    "            state = {'model': model.state_dict()}\n",
    "            torch.save(state, \"best_lcn.pt\")\n",
    "            best_score = valid_score\n",
    "\n",
    "        # \"convergent\" version\n",
    "        state = {'model': model.state_dict()}\n",
    "        torch.save(state, \"last_lcn.pt\")\n",
    "        print(train_loss, train_score, valid_loss, valid_score, test_loss, test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./LatentTrees') # replace with the actual path to the LatentTrees package\n",
    "from LatentTrees.src.LT_models import LTBinaryClassifier\n",
    "from LatentTrees.src.monitors import MonitorTree\n",
    "from LatentTrees.src.optimization import train_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LTBinaryClassifier(5, 2, reg=0.001, linear=True, split_func='linear', comp_func='concatenate')\n",
    "criterion = torch.nn.BCELoss(reduction=\"mean\")\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.5)\n",
    "monitor = MonitorTree(True, 'monitor/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss 0.013782467: 100%|██████████| 10000/10000 [15:08<00:00, 11.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# for _ in range(1):\n",
    "    # for x, y in train_loader:\n",
    "        # train_batch(x.numpy(), y.numpy(), model, optimizer, criterion, monitor=monitor)\n",
    "train_batch(train_data, train_data_labels, model, optimizer, criterion, monitor=monitor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_LatentTree(model, data_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            output = model(data)\n",
    "            output = output > 0.5\n",
    "            target = target.numpy()\n",
    "            output = output.numpy().flatten()\n",
    "            correct += np.sum(output == target)\n",
    "            total += len(target)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "valid_acc = test_LatentTree(model, valid_loader)\n",
    "test_acc = test_LatentTree(model, test_loader)\n",
    "print(valid_acc, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"best_lt.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Alternating Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from taodecisiontree import TaoTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = TaoTreeClassifier(randomize_tree=False, weight_errors=False,\n",
    "                          node_model='linear', model_args={'max_depth': 5},\n",
    "                          verbose=1, n_iters=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting score 0.7941666666666667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TaoTreeClassifier(model_args={&#x27;max_depth&#x27;: 5}, n_iters=40, node_model=&#x27;linear&#x27;,\n",
       "                  verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TaoTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>TaoTreeClassifier(model_args={&#x27;max_depth&#x27;: 5}, n_iters=40, node_model=&#x27;linear&#x27;,\n",
       "                  verbose=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TaoTreeClassifier(model_args={'max_depth': 5}, n_iters=40, node_model='linear',\n",
       "                  verbose=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(train_data, train_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc 0.7943333333333333\n",
      "Test acc 0.7986666666666666\n"
     ]
    }
   ],
   "source": [
    "print('Train acc', np.mean(m.predict(train_data) == train_data_labels))\n",
    "print('Test acc', np.mean(m.predict(test_data) == test_data_labels))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "00ad5f1807eee938f7727b558c9158a01118eae9a3a444b82c1137c2e4c2794d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
