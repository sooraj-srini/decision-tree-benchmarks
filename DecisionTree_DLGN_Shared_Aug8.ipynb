{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kjNxUX51Lh0k"
   },
   "outputs": [],
   "source": [
    "#@title Imports\n",
    "# %reset -f "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "from itertools import product as cartesian_prod\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn import cluster\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Keep this commented for generating python file\n",
    "\n",
    "# import os\n",
    "# num_layers = [4]\n",
    "# betas = [3]\n",
    "# num_neurons = [20,50,100,200,500,1000]\n",
    "\n",
    "# lrs =[0.001, 0.0001]\n",
    "\n",
    "# for num_layer in num_layers:\n",
    "#     for num_neuron in num_neurons:\n",
    "#         for beta in betas:\n",
    "#             for lr in lrs:\n",
    "#                 args = \"\"\n",
    "#                 args += \" --numlayer \"+str(num_layer)\n",
    "#                 args += \" --numnodes \"+str(num_neuron)\n",
    "#                 args += \" --beta \"+str(beta)\n",
    "#                 args += \" --lr \"+str(lr)\n",
    "#                 command = \"python Decision_tree_DLGN_expts.py \"+args\n",
    "#                 print(\"=======::::::::=========:::::::::::============\")\n",
    "#                 print(command)\n",
    "#                 os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.numlayer=4\n",
    "        self.numnodes=50\n",
    "        self.beta=3.\n",
    "        self.lr=0.001        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4_50_3_1.0e-03\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "args =  Args()\n",
    "\n",
    "num_layer = args.numlayer\n",
    "num_neuron = args.numnodes\n",
    "beta = args.beta\n",
    "lr=args.lr\n",
    "\n",
    "saved_epochs = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,18,20,22,24,26,28,30,32,64,128,256,512,1024,2048, \n",
    "                4096, 8192, 16384, 32768]\n",
    "filename_suffix = str(num_layer)\n",
    "filename_suffix += \"_\"+str(num_neuron)\n",
    "filename_suffix += \"_\"+str(int(beta))\n",
    "filename_suffix += \"_\"+format(lr,\".1e\")\n",
    "print(filename_suffix)\n",
    "\n",
    "\n",
    "no_of_batches=10 \n",
    "weight_decay=0.0\n",
    "num_hidden_nodes=[num_neuron]*num_layer\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDx4xoSOFzR2"
   },
   "source": [
    "**Variable parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2iXNxcu4L6kT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.35700969753047973 -0.1832082080887961 -0.07225476191068489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.35453505927251744 -0.5251037733746184 0.3097916878813106\n"
     ]
    }
   ],
   "source": [
    "#@title Synthetic data\n",
    "def set_npseed(seed):\n",
    "\tnp.random.seed(seed)\n",
    "\n",
    "\n",
    "def set_torchseed(seed):\n",
    "\ttorch.manual_seed(seed)\n",
    "\ttorch.cuda.manual_seed(seed)\n",
    "\ttorch.cuda.manual_seed_all(seed)\n",
    "\ttorch.backends.cudnn.deterministic = True\n",
    "\ttorch.backends.cudnn.benchmark = False\n",
    "\n",
    "#Four mode classification data\n",
    "\n",
    "\n",
    "def data_gen_decision_tree(num_data=1000, dim=2, seed=0, w_list=None, b_list=None, \n",
    "\t\t\t\t\t\t\tvals=None, num_levels=2):\n",
    "\t'''\n",
    "\tConstruct a complete decision tree with 2**num_levels-1 internal nodes, \n",
    "\te.g. num_levels=2 means there are 3 internal nodes.\n",
    "\tw_list, b_list is a list of size equal to num_internal_nodes, ie. weight and bias for each node \n",
    "\tvals is a list of size equal to num_leaf_nodes, with values +1 or -1, ie. output of each leaf node\n",
    "\t'''\n",
    "\t# np.random.seed(6790)\n",
    "\tset_npseed(seed=seed)\n",
    "\tnum_internal_nodes = 2**num_levels - 1\n",
    "\tnum_leaf_nodes = 2**num_levels\n",
    "\tstats = np.zeros(num_internal_nodes+num_leaf_nodes)\n",
    "\n",
    "\tif vals is None:\n",
    "\t\tvals = np.arange(0,num_internal_nodes+num_leaf_nodes,1,dtype=np.int32)%2\n",
    "\t\tvals[:num_internal_nodes] = -99\n",
    "\n",
    "\tif w_list is None:\n",
    "\t\tw_list = np.random.standard_normal((num_internal_nodes, dim))\n",
    "\t\tw_list = w_list/np.linalg.norm(w_list, axis=1)[:, None]\n",
    "\t\tb_list = np.zeros((num_internal_nodes))\n",
    "\n",
    "\tdata_x = np.random.random_sample((num_data, dim))*2 - 1.\n",
    "\trelevant_stats = data_x @ w_list.T + b_list\n",
    "\t\n",
    "\tprint(relevant_stats[0,0], relevant_stats[0,1], relevant_stats[0,2])\n",
    "\tcurr_index = np.zeros(shape=(num_data), dtype=int)\n",
    "\t\n",
    "\tfor level in range(num_levels):\n",
    "\t\tnodes_curr_level=list(range(2**level - 1,2**(level+1)-1  ))\n",
    "\t\tfor el in nodes_curr_level:\n",
    "\t\t\tb_list[el]=-1*np.median(relevant_stats[curr_index==el,el])\n",
    "\t\t\trelevant_stats[:,el] += b_list[el]\n",
    "\t\tdecision_variable = np.choose(curr_index, relevant_stats.T) \n",
    "\t\t# Go down and right if wx+b>0 down and left otherwise. \n",
    "\t\t# i.e. 0 -> 1 if w[0]x+b[0]<0 and 0->2 otherwise\n",
    "\t\tcurr_index = (curr_index+1)*2 - (1-(decision_variable > 0))\n",
    "\n",
    "\tbound_dist = np.min(np.abs(relevant_stats), axis=1)\n",
    "\tthres = 0.1\n",
    "\tprint(relevant_stats[0,0], relevant_stats[0,1], relevant_stats[0,2])\n",
    "\tlabels = vals[curr_index]\n",
    "\tdata_x_pruned = data_x[bound_dist>thres]\n",
    "\tlabels_pruned = labels[bound_dist>thres]\n",
    "\trelevant_stats = np.sign(data_x_pruned @ w_list.T + b_list)\n",
    "\tnodes_active = np.zeros((len(data_x_pruned),  num_internal_nodes+num_leaf_nodes), dtype=np.int32)\n",
    "\tfor node in range(num_internal_nodes+num_leaf_nodes):\n",
    "\t\tif node==0:\n",
    "\t\t\tstats[node]=len(relevant_stats)\n",
    "\t\t\tnodes_active[:,0]=1\n",
    "\t\t\tcontinue\n",
    "\t\tparent = (node-1)//2\n",
    "\t\tnodes_active[:,node]=nodes_active[:,parent]\n",
    "\t\tright_child = node-(parent*2)-1 # 0 means left, 1 means right 1 has children 3,4\n",
    "\t\tif right_child==1:\n",
    "\t\t\tnodes_active[:,node] *= relevant_stats[:,parent]>0\n",
    "\t\tif right_child==0:\n",
    "\t\t\tnodes_active[:,node] *= relevant_stats[:,parent]<0\t\t\n",
    "\t\tstats = nodes_active.sum(axis=0)\n",
    "\treturn ((data_x_pruned, labels_pruned), (w_list, b_list, vals), stats)\n",
    "\n",
    "\n",
    "# w_list = np.array([[1., 0], [0, 1], [0, 1]])\n",
    "# b_list = np.array([0, 0.25, -0.25])\n",
    "# vals = np.array([-99, -99, -99, 0, 1, 1, 0])\n",
    "num_data = 300000\n",
    "input_dim= 2 \n",
    "seeds = np.random.randint(0,10000,100)\n",
    "seeds=[1387]\n",
    "# seeds = [2318]\n",
    "for seed in seeds:\n",
    "\t((data_x, labels), (w_list, b_list, vals), stats) = data_gen_decision_tree(\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tdim=input_dim, seed=seed, num_levels=5,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tnum_data=num_data)\n",
    "\tseed_set=seed\n",
    "w_list_old = np.array(w_list)\n",
    "b_list_old = np.array(b_list)\n",
    "\n",
    "num_data = len(data_x)\n",
    "num_train= num_data//2\n",
    "num_vali = num_data//4\n",
    "num_test = num_data//4\n",
    "train_data = data_x[:num_train,:]\n",
    "train_data_labels = labels[:num_train]\n",
    "\n",
    "vali_data = data_x[num_train:num_train+num_vali,:]\n",
    "vali_data_labels = labels[num_train:num_train+num_vali]\n",
    "\n",
    "test_data = data_x[num_train+num_vali :,:]\n",
    "test_data_labels = labels[num_train+num_vali :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.44, -0.9 ]),\n",
       " array([0.09, 1.  ]),\n",
       " 0.0024746382579622804,\n",
       " -0.8565583954664894,\n",
       " 8447)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_list[0],data_x[0],b_list[0],(w_list[0]@data_x[0]),num_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(data_x, labels, w_list, b_list, vals):\n",
    "    freq = np.zeros(len(vals))\n",
    "    for i, x in enumerate(data_x):\n",
    "        current_index = 1\n",
    "        while current_index < 32:\n",
    "            output = w_list[current_index-1]@x + b_list[current_index-1]\n",
    "            current_index *= 2\n",
    "            if output >= 0:\n",
    "                current_index += 1\n",
    "        if vals[current_index-1] == 1 and labels[i] != 1:\n",
    "            return False\n",
    "        if vals[current_index-1] == -1 and labels[i] != 0:\n",
    "            return False\n",
    "        if labels[i] == 0:\n",
    "            freq[current_index-1]-=1\n",
    "        else:\n",
    "            freq[current_index-1]+=1\n",
    "    return True, freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " array([    0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,     0.,  -290.,   122.,     0.,     0.,  -613.,     0.,\n",
       "           -6.,   865.,     0.,   149.,  -444.,   135.,    -9.,     0.,\n",
       "         -430.,     0.,     0.,   309., -1512.,   130.,     0.,    13.,\n",
       "            0.,     0., -1323.,   264.,  -227.,  1168.,  -438.]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check(data_x, labels, w_list, b_list, vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DLGN_FC(nn.Module):\n",
    "\tdef __init__(self, input_dim=None, output_dim=None, num_hidden_nodes=[], beta=30, mode='pwc'):\t\t\n",
    "\t\tsuper(DLGN_FC, self).__init__()\n",
    "\t\tself.num_hidden_layers = len(num_hidden_nodes)\n",
    "\t\tself.beta=beta  # Soft gating parameter\n",
    "\t\tself.mode = mode\n",
    "\t\tself.num_nodes=[input_dim]+num_hidden_nodes+[output_dim]\n",
    "\t\tself.gating_layers=nn.ModuleList()\n",
    "\t\tself.value_layers=nn.ModuleList()\n",
    "\t\t\n",
    "\t\tfor i in range(self.num_hidden_layers+1):\n",
    "\t\t\tif i!=self.num_hidden_layers:\n",
    "\t\t\t\ttemp = nn.Linear(self.num_nodes[i], self.num_nodes[i+1])\n",
    "\t\t\t\t# a = temp.weight.detach() \n",
    "\t\t\t\t# a /= a.norm(dim=1, keepdim=True)\n",
    "\t\t\t\tself.gating_layers.append(temp)\n",
    "\t\t\ttemp = nn.Linear(self.num_nodes[i], self.num_nodes[i+1], bias=False)\n",
    "\t\t\t# a = temp.weight.detach()\n",
    "\t\t\t# a /= a.norm(dim=1, keepdim=True)\n",
    "\t\t\tself.value_layers.append(temp)\n",
    "\n",
    "\n",
    "\tdef set_parameters_with_mask(self, to_copy, parameter_masks):\n",
    "\t\t# self and to_copy are DLGN_FC objects with same architecture\n",
    "\t\t# parameter_masks is compatible with dict(to_copy.named_parameters())\n",
    "\t\tfor (name, copy_param) in to_copy.named_parameters():\n",
    "\t\t\tcopy_param = copy_param.clone().detach()\n",
    "\t\t\torig_param  = self.state_dict()[name]\n",
    "\t\t\tif name in parameter_masks:\n",
    "\t\t\t\tparam_mask = parameter_masks[name]>0\n",
    "\t\t\t\torig_param[param_mask] = copy_param[param_mask]\n",
    "\t\t\telse:\n",
    "\t\t\t\torig_param = copy_param.data.detach()\n",
    "\t\n",
    "\n",
    "\t\t\t\t\t\t\t\t\n",
    "\n",
    "\tdef return_gating_functions(self):\n",
    "\t\teffective_weights = []\n",
    "\t\teffective_biases =[]\n",
    "\t\tfor i in range(self.num_hidden_layers):\n",
    "\t\t\tcurr_weight = self.gating_layers[i].weight.detach()\n",
    "\t\t\tcurr_bias = self.gating_layers[i].bias.detach()\n",
    "\t\t\tif i==0:\n",
    "\t\t\t\teffective_weights.append(curr_weight)\n",
    "\t\t\t\teffective_biases.append(curr_bias)\n",
    "\t\t\telse:\n",
    "\t\t\t\teffective_biases.append(torch.matmul(curr_weight,effective_biases[-1])+curr_bias)\n",
    "\t\t\t\teffective_weights.append(torch.matmul(curr_weight,effective_weights[-1]))\n",
    "\t\treturn effective_weights, effective_biases\n",
    "\t\t# effective_weights (and effective biases) is a list of size num_hidden_layers\n",
    "\t\t\t\t\t\t\t\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tgate_scores=[x]\n",
    "\n",
    "\t\tfor el in self.parameters():\n",
    "\t\t\tif el.is_cuda:\n",
    "\t\t\t\tdevice = torch.device('cuda')\n",
    "\t\t\telse:\n",
    "\t\t\t\tdevice = torch.device('cpu')\n",
    "\t\tif self.mode=='pwc':\n",
    "\t\t\tvalues=[torch.ones(x.shape).to(device)]\n",
    "\t\telse:\n",
    "\t\t\tvalues=[x]\n",
    "\t\t\n",
    "\t\tfor i in range(self.num_hidden_layers):\n",
    "\t\t\tgate_scores.append(self.gating_layers[i](gate_scores[-1]))\n",
    "\t\t\tcurr_gate_on_off = torch.sigmoid(self.beta * gate_scores[-1])\n",
    "\t\t\tvalues.append(self.value_layers[i](values[-1])*curr_gate_on_off)\n",
    "\t\tvalues.append(self.value_layers[self.num_hidden_layers](values[-1]))\n",
    "\t\t# Values is a list of size 1+num_hidden_layers+1\n",
    "\t\t#gate_scores is a list of size 1+num_hidden_layers\n",
    "\t\treturn values,gate_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Ncr5k6koMbD_"
   },
   "outputs": [],
   "source": [
    "#@title Train DLGN model\n",
    "def train_dlgn (DLGN_obj, train_data_curr,vali_data_curr,test_data_curr,\n",
    "\t\t\t\ttrain_labels_curr,test_labels_curr,vali_labels_curr,num_epoch=1,\n",
    "\t\t\t\tparameter_mask=dict()):\n",
    "\t\n",
    "\tdevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\tDLGN_obj.to(device)\n",
    "\n",
    "\tcriterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\toptimizer = optim.Adam(DLGN_obj.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "\n",
    "\ttrain_data_torch = torch.Tensor(train_data_curr)\n",
    "\tvali_data_torch = torch.Tensor(vali_data_curr)\n",
    "\ttest_data_torch = torch.Tensor(test_data_curr)\n",
    "\n",
    "\ttrain_labels_torch = torch.tensor(train_labels_curr, dtype=torch.int64)\n",
    "\ttest_labels_torch = torch.tensor(test_labels_curr, dtype=torch.int64)\n",
    "\tvali_labels_torch = torch.tensor(vali_labels_curr, dtype=torch.int64)\n",
    "\n",
    "\tnum_batches = no_of_batches\n",
    "\tbatch_size = len(train_data_curr)//num_batches\n",
    "\tlosses=[]\n",
    "\tDLGN_obj_store = []\n",
    "\tbest_vali_error = len(vali_labels_curr)\n",
    "\t\n",
    "\n",
    "\t# print(\"H3\")\n",
    "\t# print(DLGN_params)\n",
    "\ttrain_losses = []\n",
    "\trunning_loss = 0.7*num_batches # initial random loss = 0.7 \n",
    "\tfor epoch in tqdm(range(saved_epochs[-1])):  # loop over the dataset multiple times\n",
    "\t\tif epoch in saved_epochs:\n",
    "\t\t\tDLGN_obj_copy = deepcopy(DLGN_obj)\n",
    "\t\t\tDLGN_obj_copy.to(torch.device('cpu'))\n",
    "\t\t\tDLGN_obj_store.append(DLGN_obj_copy)\n",
    "\t\t\ttrain_losses.append(running_loss/num_batches)\n",
    "\t\t\tif running_loss/num_batches < 1e-5:\n",
    "\t\t\t\tbreak\n",
    "\t\trunning_loss = 0.0\n",
    "\t\tfor batch_start in range(0,len(train_data_curr),batch_size):\n",
    "\t\t\tif (batch_start+batch_size)>len(train_data_curr):\n",
    "\t\t\t\tbreak\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\tinputs = train_data_torch[batch_start:batch_start+batch_size]\n",
    "\t\t\ttargets = train_labels_torch[batch_start:batch_start+batch_size].reshape(batch_size)\n",
    "\t\t\tinputs = inputs.to(device)\n",
    "\t\t\ttargets = targets.to(device)\n",
    "\t\t\tvalues,gate_scores = DLGN_obj(inputs)\n",
    "\t\t\toutputs = torch.cat((-1*values[-1], values[-1]), dim=1)\n",
    "\t\t\tloss = criterion(outputs, targets)\t\t\t\n",
    "\t\t\tloss.backward()\n",
    "\t\t\tfor name,param in DLGN_obj.named_parameters():\n",
    "\t\t\t\tparameter_mask[name] = parameter_mask[name].to(device)\n",
    "\t\t\t\tparam.grad *= parameter_mask[name]   \n",
    "\t\t\toptimizer.step()\n",
    "\t\t\trunning_loss += loss.item()    \n",
    "\t\tlosses.append(running_loss/num_batches)\n",
    "\t\tinputs = vali_data_torch.to(device)\n",
    "\t\ttargets = vali_labels_torch.to(device)\n",
    "\t\tvalues,gate_scores =DLGN_obj(inputs)\n",
    "\t\tvali_preds = torch.cat((-1*values[-1], values[-1]), dim=1)\n",
    "\t\tvali_preds = torch.argmax(vali_preds, dim=1)\n",
    "\t\tvali_error= torch.sum(targets!=vali_preds)\n",
    "\t\tif vali_error < best_vali_error:\n",
    "\t\t\tDLGN_obj_return = deepcopy(DLGN_obj)\n",
    "\t\t\tbest_vali_error = vali_error\n",
    "\tplt.figure()\n",
    "\tplt.title(\"DLGN loss vs epoch\")\n",
    "\tplt.plot(losses)\n",
    "\tif not os.path.exists('figures'):\n",
    "\t\tos.mkdir('figures')\n",
    "\n",
    "\tfilename = 'figures/'+filename_suffix +'.pdf'\n",
    "\tplt.savefig(filename)\n",
    "\tDLGN_obj_return.to(torch.device('cpu'))\n",
    "\tdevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\treturn train_losses, DLGN_obj_return, DLGN_obj_store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PpN8Yby7Fllw"
   },
   "source": [
    "**Training a DLGN model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368
    },
    "id": "LF7PO4Lc2jzV",
    "outputId": "5858b9a2-48bb-4fdb-9d55-f37981c6f839"
   },
   "outputs": [],
   "source": [
    "set_torchseed(6675)\n",
    "# set_torchseed(5449)\n",
    "DLGN_init= DLGN_FC(input_dim=input_dim, output_dim=1, num_hidden_nodes=num_hidden_nodes, beta=beta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 256/32768 [00:06<14:36, 37.11it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGzCAYAAAD9pBdvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA+bklEQVR4nO3de3hU5b328Xsmh0lCSAIEJgQj4YzIIRYkTRGwNRotWqltd7BqMJfirsVWTevWaAtqtdFqkVZpsVZqt9aCuD22FsUg+lpTUZAqoEGoEA6ZQMBkQkIOZJ73j2QGhiSQgWTWJPP9XNe6IGueteY3i5jcPoe1bMYYIwAAAIvYrS4AAACEN8IIAACwFGEEAABYijACAAAsRRgBAACWIowAAABLEUYAAIClCCMAAMBShBEAAGApwggAP9dee63S09OtLgPHeOqpp2Sz2fThhx9aXQrQLQgjwGnw/pLwbjExMUpNTVVOTo5++9vfqqamps0xd999t2w2myorK096/n379umOO+7QhAkTFB8fr5iYGI0cOVL5+fl69913260lJiZGe/bsaXOu888/X+PHjz/1DwsA3STS6gKA3uDee+/VsGHD1NTUJJfLpbVr1+qWW27RokWL9Morr2jixIkBn3PdunWaNWuWampqNGfOHP3gBz+Qw+HQF198oZdeeklPPfWU3n77bc2YMcPvuIaGBj3wwAN69NFHu+rjAUC3IowAXeCSSy7RlClTfF8XFhZqzZo1uvTSS/Wtb31Ln376qWJjYzt9vi+//FKzZ89WZGSkNm7cqLFjx/q9ft9992n58uXtnjMjI0NPPPGECgsLlZqaeuofCgCChGEaoJt84xvf0M9//nPt3LlTzzzzTEDHLl26VOXl5Vq8eHGbICJJNptNV155pc4999w2r915551qbm7WAw88cMq1H6+2tlY/+clPlJaWJofDoTFjxujhhx/W8Q/9Xr16tc477zwlJSUpPj5eY8aM0Z133unX5tFHH9XZZ5+tuLg49evXT1OmTNGzzz7b4XtXVFQoMjJS99xzT5vXSktLZbPZ9Nhjj0mSmpqadM8992jUqFGKiYnRgAEDdN5552n16tUn/YxVVVW65ZZbfJ9x5MiRevDBB+XxeHxtduzYIZvNpocffliPPPKIhg4dqtjYWM2cOVObNm1qc841a9Zo+vTp6tOnj5KSknT55Zfr008/bdNuz549uu6665SamiqHw6Fhw4bpxhtvVGNjo1+7hoYGFRQUaODAgerTp4++/e1va//+/Sf9bECoo2cE6EbXXHON7rzzTr3xxhuaN29ep4979dVXFRsbqyuuuCLg9xw2bJjy8vL0xBNP6I477jjt3hFjjL71rW/prbfe0nXXXaeMjAy9/vrruu2227Rnzx498sgjkqTNmzfr0ksv1cSJE3XvvffK4XBo27Zt+uc//+k71xNPPKEf//jH+u53v6ubb75Z9fX1+vjjj/X+++/r+9//frvv73Q6NXPmTD333HNauHCh32srVqxQRESEvve970lqmY9TVFSk66+/XlOnTpXb7daHH36oDRs26MILL+zwM9bV1WnmzJnas2eP/vu//1tnnnmm3nvvPRUWFvpC4bH+93//VzU1NZo/f77q6+v1m9/8Rt/4xjf0ySefyOl0SpLefPNNXXLJJRo+fLjuvvtuHT58WI8++qimTZumDRs2+CYJ7927V1OnTlVVVZVuuOEGjR07Vnv27NHzzz+vuro6RUdH+973Rz/6kfr166eFCxdqx44dWrx4sW666SatWLGic/+YQKgyAE7Zn/70JyPJfPDBBx22SUxMNOecc47v64ULFxpJZv/+/R0e069fP5ORkdFmv9vtNvv37/dthw4dareW7du3m8jISPPjH//Y9/rMmTPN2WeffdLPNHfuXDN06FDf1y+99JKRZO677z6/dt/97neNzWYz27ZtM8YY88gjj5z0c11++eWdquF4jz/+uJFkPvnkE7/948aNM9/4xjd8X0+aNMnMmjUr4PP/4he/MH369DFbt27123/HHXeYiIgIU1ZWZowx5osvvjCSTGxsrNm9e7ev3fvvv28kmVtvvdW3LyMjwwwaNMgcOHDAt+/f//63sdvtJi8vz7cvLy/P2O32dr+HPB6PMebov212drZvnzHG3HrrrSYiIsJUVVUF/JmBUMIwDdDN4uPj211VcyJut1vx8fFt9l9zzTUaOHCgb7v99tvbPX748OG65ppr9Ic//EHl5eWnVLfXa6+9poiICP34xz/22/+Tn/xExhj94x//kCQlJSVJkl5++WW/oY1jJSUlaffu3frggw8CquGKK65QZGSkXw/Apk2btGXLFuXm5vqdf/Pmzfr8888DOv/KlSs1ffp09evXT5WVlb4tOztbzc3Neuedd/zaz549W0OGDPF9PXXqVGVmZuq1116TJJWXl2vjxo269tpr1b9/f1+7iRMn6sILL/S183g8eumll3TZZZf5zTnystlsfl/fcMMNfvumT5+u5uZm7dy5M6DPC4QawgjQzQ4dOqS+ffsGdEzfvn116NChNvvvvfderV69ulNzIH72s5/pyJEjpz13ZOfOnUpNTW3zGc466yzf65KUm5uradOm6frrr5fT6dScOXP03HPP+QWT22+/XfHx8Zo6dapGjRql+fPn+w3jdCQ5OVkXXHCBnnvuOd++FStWKDIy0m8o695771VVVZVGjx6tCRMm6LbbbtPHH3980vN//vnnWrVqlV/QGzhwoLKzsyW1LLE+1qhRo9qcY/To0dqxY4ffNRkzZkybdmeddZYqKytVW1ur/fv3y+12d3rJ9Zlnnun3db9+/SS1THgGejLCCNCNdu/ererqao0cOTKg48aOHavS0lI1NTX57Z84caKys7N9vyRPZPjw4br66qu7pHekM2JjY/XOO+/ozTff1DXXXKOPP/5Yubm5uvDCC9Xc3Cyp5RdxaWmpli9frvPOO0//93//p/POO6/NXJD2zJkzR1u3btXGjRslSc8995wuuOACJScn+9rMmDFD27dv17JlyzR+/Hj98Y9/1Fe+8hX98Y9/POG5PR6PLrzwQl/QO377zne+c+oXpgtFRES0u98cN5EY6GkII0A3evrppyVJOTk5AR136aWX6vDhw3rxxRdP6/29vSMPPvjgKZ9j6NCh2rt3b5uhps8++8z3upfdbtcFF1ygRYsWacuWLbr//vu1Zs0avfXWW742ffr0UW5urv70pz+prKxMs2bN0v3336/6+voT1jF79mxFR0drxYoV2rhxo7Zu3ao5c+a0ade/f3/l5+frr3/9q3bt2qWJEyfq7rvvPuG5R4wYoUOHDvmC3vHb8T0S7Q0Dbd261Tcp1XtNSktL27T77LPPlJycrD59+mjgwIFKSEhodyUOEE4II0A3WbNmjX7xi19o2LBhuuqqqwI69sYbb5TT6dStt96qrVu3tnm9s/8nPGLECF199dV6/PHH5XK5AqrB65vf/Kaam5t9y2e9HnnkEdlsNl1yySWSpIMHD7Y5NiMjQ1LLklRJOnDggN/r0dHRGjdunIwxbXqBjpeUlKScnBw999xzWr58uaKjozV79my/NsefPz4+XiNHjvS9f0f+67/+SyUlJXr99dfbvFZVVaUjR4747XvppZf87nK7bt06vf/++75rMXjwYGVkZOjPf/6zqqqqfO02bdqkN954Q9/85jcltYS32bNn69VXX233Vu/0eCBcsLQX6AL/+Mc/9Nlnn+nIkSOqqKjQmjVrtHr1ag0dOlSvvPKKYmJi2hyzaNEixcXF+e2z2+2688471b9/f7344ou67LLLNGnSJM2ZM0fnnnuuoqKitGvXLq1cuVJS2zkE7bnrrrv09NNPq7S0VGeffXbAn+2yyy7T17/+dd11113asWOHJk2apDfeeEMvv/yybrnlFo0YMUJSy3yNd955R7NmzdLQoUO1b98+/e53v9MZZ5yh8847T5J00UUXKSUlRdOmTZPT6dSnn36qxx57TLNmzerUvJrc3FxdffXV+t3vfqecnBzfpFmvcePG6fzzz9fkyZPVv39/ffjhh3r++ed10003nfC8t912m1555RVdeumluvbaazV58mTV1tbqk08+0fPPP68dO3b4DQeNHDlS5513nm688UY1NDRo8eLFGjBggP7nf/7H1+ahhx7SJZdcoqysLF133XW+pb2JiYl+PTW//OUv9cYbb2jmzJm64YYbdNZZZ6m8vFwrV67Uu+++2+YzAr2SpWt5gB7Ou+TSu0VHR5uUlBRz4YUXmt/85jfG7Xa3Oca7tLe9LSIiwq9teXm5ue2228y4ceNMbGyscTgcZvjw4SYvL8+888477dbS3hLRuXPnGkmntLTXGGNqamrMrbfealJTU01UVJQZNWqUeeihh/yWmRYXF5vLL7/cpKammujoaJOammquvPJKv+Wyjz/+uJkxY4YZMGCAcTgcZsSIEea2224z1dXVJ63LmJalzbGxsUaSeeaZZ9q8ft9995mpU6eapKQkExsba8aOHWvuv/9+09jYeNJz19TUmMLCQjNy5EgTHR1tkpOTzde+9jXz8MMP+473Lu196KGHzK9//WuTlpZmHA6HmT59uvn3v//d5pxvvvmmmTZtmomNjTUJCQnmsssuM1u2bGnTbufOnSYvL88MHDjQ9288f/5809DQYIzp+N/2rbfeMpLMW2+91ZnLB4QsmzH0AwJAZ+zYsUPDhg3TQw89pJ/+9KdWlwP0GswZAQAAliKMAAAASxFGAACApZgzAgAALEXPCAAAsBRhBAAAWKpH3PTM4/Fo79696tu3b5unWAIAgNBkjFFNTY1SU1Nlt3fc/9EjwsjevXuVlpZmdRkAAOAU7Nq1S2eccUaHr/eIMOK9TfSuXbuUkJBgcTUAAKAz3G630tLSTvq4hx4RRrxDMwkJCYQRAAB6mJNNsTilCaxLlixRenq6YmJilJmZqXXr1nXY9vzzz5fNZmuzzZo161TeGgAA9DIBh5EVK1aooKBACxcu1IYNGzRp0iTl5ORo37597bZ/4YUXVF5e7ts2bdqkiIgIfe973zvt4gEAQM8XcBhZtGiR5s2bp/z8fI0bN05Lly5VXFycli1b1m77/v37KyUlxbetXr1acXFxJwwjDQ0NcrvdfhsAAOidAgojjY2NWr9+vbKzs4+ewG5Xdna2SkpKOnWOJ598UnPmzFGfPn06bFNUVKTExETfxkoaAAB6r4DCSGVlpZqbm+V0Ov32O51OuVyukx6/bt06bdq0Sddff/0J2xUWFqq6utq37dq1K5AyAQBADxLU1TRPPvmkJkyYoKlTp56wncPhkMPhCFJVAADASgH1jCQnJysiIkIVFRV++ysqKpSSknLCY2tra7V8+XJdd911gVcJAAB6rYDCSHR0tCZPnqzi4mLfPo/Ho+LiYmVlZZ3w2JUrV6qhoUFXX331qVUKAAB6pYCHaQoKCjR37lxNmTJFU6dO1eLFi1VbW6v8/HxJUl5enoYMGaKioiK/45588knNnj1bAwYM6JrKAQBArxBwGMnNzdX+/fu1YMECuVwuZWRkaNWqVb5JrWVlZW0ehlNaWqp3331Xb7zxRtdUDQAAeg2bMcZYXcTJuN1uJSYmqrq6mtvBAwDQQ3T29/cp3Q4eAACgq/SIB+V1l2XvfqEdB2p19VeHarTzxE8UBAAA3SOse0Ze/Xiv/rdkp3ZU1lpdCgAAYSusw0if6JaOobrGZosrAQAgfIV1GImLjpAkHWo4YnElAACEr7AOI30c3p4RwggAAFYJ8zDS0jNS28AwDQAAVgnvMBJNzwgAAFYL6zAS1xpGDtEzAgCAZcI6jHiHaegZAQDAOmEeRlp6RpgzAgCAdcI6jHiX9tIzAgCAdcI6jHgnsNZynxEAACwT1mEkzru0lzuwAgBgmbAOI/Hem57RMwIAgGXCOox4l/bSMwIAgHXCOoywtBcAAOuFdRjx9ow0NRs1HKF3BAAAK4R1GOnTurRXkuq41wgAAJYI6zASGWGXI7LlEtQyVAMAgCXCOoxIR+/CWsckVgAALBH2YcR7F9ZDLO8FAMASYR9GvHdhZc4IAADWIIz47sJKzwgAAFYgjPjmjBBGAACwQtiHkaNzRhimAQDACmEfRo7OGaFnBAAAKxBGHDyfBgAAK4V9GInzPp+GnhEAACwR9mGkD0/uBQDAUmEfRrwTWGvpGQEAwBJhH0biWdoLAIClwj6MxHknsLK0FwAAS4R9GOnTOkxDzwgAANYI+zAS1zqBlQflAQBgjbAPI95n09SxmgYAAEsQRnxzRugZAQDACoQR7+3gG5tljLG4GgAAws8phZElS5YoPT1dMTExyszM1Lp1607YvqqqSvPnz9fgwYPlcDg0evRovfbaa6dUcFfz3oH1iMeosdljcTUAAISfyEAPWLFihQoKCrR06VJlZmZq8eLFysnJUWlpqQYNGtSmfWNjoy688EINGjRIzz//vIYMGaKdO3cqKSmpK+o/bd6eEallea8jMsLCagAACD8Bh5FFixZp3rx5ys/PlyQtXbpUf//737Vs2TLdcccdbdovW7ZMBw8e1HvvvaeoqChJUnp6+ulV3YUi7DZFRdjU1GxU38QkVgAAgi2gYZrGxkatX79e2dnZR09gtys7O1slJSXtHvPKK68oKytL8+fPl9Pp1Pjx4/XLX/5Szc0d/+JvaGiQ2+3227pTTGtvCGEEAIDgCyiMVFZWqrm5WU6n02+/0+mUy+Vq95j//Oc/ev7559Xc3KzXXntNP//5z/XrX/9a9913X4fvU1RUpMTERN+WlpYWSJkBc0R5wwhzRgAACLZuX03j8Xg0aNAg/eEPf9DkyZOVm5uru+66S0uXLu3wmMLCQlVXV/u2Xbt2dWuNMVEtl6H+CD0jAAAEW0BzRpKTkxUREaGKigq//RUVFUpJSWn3mMGDBysqKkoREUcnhp511llyuVxqbGxUdHR0m2McDoccDkcgpZ2WmCiGaQAAsEpAPSPR0dGaPHmyiouLffs8Ho+Ki4uVlZXV7jHTpk3Ttm3b5PEcHQLZunWrBg8e3G4QsYK3Z6SBYRoAAIIu4GGagoICPfHEE/rzn/+sTz/9VDfeeKNqa2t9q2vy8vJUWFjoa3/jjTfq4MGDuvnmm7V161b9/e9/1y9/+UvNnz+/6z7FaWICKwAA1gl4aW9ubq7279+vBQsWyOVyKSMjQ6tWrfJNai0rK5PdfjTjpKWl6fXXX9ett96qiRMnasiQIbr55pt1++23d92nOE3eYZqGI/SMAAAQbDbTA+6B7na7lZiYqOrqaiUkJHT5+a//8wd689N9euCKCZoz9cwuPz8AAOGos7+/w/7ZNNKxS3sZpgEAINgIIzpmzgjDNAAABB1hRMfcZ4SeEQAAgo4womPvM0LPCAAAwUYYkeSIpGcEAACrEEZ07NJewggAAMFGGNGxc0YYpgEAINgII+LZNAAAWIkwIm4HDwCAlQgjkhwM0wAAYBnCiI4ZpmECKwAAQUcY0TGraegZAQAg6AgjkmK89xmhZwQAgKAjjIieEQAArEQYEUt7AQCwEmFEPCgPAAArEUZ07GoahmkAAAg2woiO3vSs2WPU1EwgAQAgmAgjOnrTM4mhGgAAgo0wIskRaZfN1vJ37sIKAEBwEUYk2Ww2OSKZxAoAgBUII60crfNGGrjxGQAAQUUYaRXDw/IAALAEYaQVNz4DAMAahJFWMb5hGnpGAAAIJsJIK+7CCgCANQgjrRy+YRp6RgAACCbCSCvmjAAAYA3CSKsY731GWNoLAEBQEUZaxTBMAwCAJQgjrZjACgCANQgjrbw9Iw2EEQAAgoow0so3TMN9RgAACCrCSKsYHpQHAIAlCCOtHCztBQDAEoSRVqymAQDAGoSRVqymAQDAGoSRVjwoDwAAa5xSGFmyZInS09MVExOjzMxMrVu3rsO2Tz31lGw2m98WExNzygV3Fwc9IwAAWCLgMLJixQoVFBRo4cKF2rBhgyZNmqScnBzt27evw2MSEhJUXl7u23bu3HlaRXcHb88IS3sBAAiugMPIokWLNG/ePOXn52vcuHFaunSp4uLitGzZsg6PsdlsSklJ8W1Op/O0iu4O3PQMAABrBBRGGhsbtX79emVnZx89gd2u7OxslZSUdHjcoUOHNHToUKWlpenyyy/X5s2bT/g+DQ0Ncrvdflt3i3O0hJHaxiPd/l4AAOCogMJIZWWlmpub2/RsOJ1OuVyudo8ZM2aMli1bppdfflnPPPOMPB6Pvva1r2n37t0dvk9RUZESExN9W1paWiBlnpKEmChJUnVdU7e/FwAAOKrbV9NkZWUpLy9PGRkZmjlzpl544QUNHDhQjz/+eIfHFBYWqrq62rft2rWru8tUYmxLGKlpOCKPx3T7+wEAgBaRgTROTk5WRESEKioq/PZXVFQoJSWlU+eIiorSOeeco23btnXYxuFwyOFwBFLaafOGEWOkmvojSoyLCur7AwAQrgLqGYmOjtbkyZNVXFzs2+fxeFRcXKysrKxOnaO5uVmffPKJBg8eHFil3Sw60q7Y1kms7nqGagAACJaAekYkqaCgQHPnztWUKVM0depULV68WLW1tcrPz5ck5eXlaciQISoqKpIk3XvvvfrqV7+qkSNHqqqqSg899JB27typ66+/vms/SRdIjI3S4aZmVR9uUvfPUgEAANIphJHc3Fzt379fCxYskMvlUkZGhlatWuWb1FpWVia7/WiHy5dffql58+bJ5XKpX79+mjx5st577z2NGzeu6z5FF0mIjZTLLVUfpmcEAIBgsRljQn62ptvtVmJioqqrq5WQkNBt7/O9pe/pgx1f6ndXfUXfnBBaw0gAAPQ0nf39zbNpjuGdxErPCAAAwUMYOUYCYQQAgKAjjByDnhEAAIKPMHIMbxhxE0YAAAgawsgxfLeEJ4wAABA0hJFjMEwDAEDwEUaOwTANAADBRxg5hvd5NPSMAAAQPISRYzBMAwBA8BFGjuEbpqk/oh5wY1oAAHoFwsgxvKtpmj1GtY3NFlcDAEB4IIwcIybKruiIlkvCUA0AAMFBGDmGzWY7ekv4OsIIAADBQBg5TmJspCR6RgAACBbCyHFYUQMAQHARRo7Djc8AAAguwshx6BkBACC4CCPHSfDda4QwAgBAMBBGjkPPCAAAwUUYOc6APtGSpP01DRZXAgBAeCCMHGdwUqwkaW91vcWVAAAQHggjx0lNbA0jVYctrgQAgPBAGDlOalKMJKnyUIMaj3gsrgYAgN6PMHKc/n2i5Yi0yxipws1QDQAA3Y0wchybzabU1nkjexiqAQCg2xFG2jE4sWWopryaMAIAQHcjjLRjsG8SK8M0AAB0N8JIO4a0TmJlRQ0AAN2PMNIO771GyrnXCAAA3Y4w0g7vBFZ6RgAA6H6EkXakJjJMAwBAsBBG2uEdpnHXH9GhhiMWVwMAQO9GGGlHvCNSCTGRkqRyekcAAOhWhJEOpPLAPAAAgoIw0oEhrWGk7GCdxZUAANC7EUY6MNIZL0na6qqxuBIAAHo3wkgHxqb0lSSVEkYAAOhWhJEOjHEmSJI+c7lljLG4GgAAei/CSAdGDOqjCLtN7vojcrmZxAoAQHc5pTCyZMkSpaenKyYmRpmZmVq3bl2njlu+fLlsNptmz559Km8bVI7ICA1P7iNJ+oyhGgAAuk3AYWTFihUqKCjQwoULtWHDBk2aNEk5OTnat2/fCY/bsWOHfvrTn2r69OmnXGywjWHeCAAA3S7gMLJo0SLNmzdP+fn5GjdunJYuXaq4uDgtW7asw2Oam5t11VVX6Z577tHw4cNPq+BgYhIrAADdL6Aw0tjYqPXr1ys7O/voCex2ZWdnq6SkpMPj7r33Xg0aNEjXXXddp96noaFBbrfbb7PCmJSWSayfllvz/gAAhIOAwkhlZaWam5vldDr99judTrlcrnaPeffdd/Xkk0/qiSee6PT7FBUVKTEx0belpaUFUmaX8faMbN9/SE3NHktqAACgt+vW1TQ1NTW65ppr9MQTTyg5ObnTxxUWFqq6utq37dq1qxur7NiQpFjFOyLV1Gy0ff8hS2oAAKC3iwykcXJysiIiIlRRUeG3v6KiQikpKW3ab9++XTt27NBll13m2+fxtPQwREZGqrS0VCNGjGhznMPhkMPhCKS0bmG32zR+SIL+9Z+D2lhWpbGtwzYAAKDrBNQzEh0drcmTJ6u4uNi3z+PxqLi4WFlZWW3ajx07Vp988ok2btzo2771rW/p61//ujZu3GjZ8EsgMtL6SZI27qqythAAAHqpgHpGJKmgoEBz587VlClTNHXqVC1evFi1tbXKz8+XJOXl5WnIkCEqKipSTEyMxo8f73d8UlKSJLXZH6rOOTNJEmEEAIDuEnAYyc3N1f79+7VgwQK5XC5lZGRo1apVvkmtZWVlstt7z41dz0lLkiSVVtToUMMRxTsCvmQAAOAEbKYHPHjF7XYrMTFR1dXVSkgI/ryNrxUVa291vZ6dl6mvjej8RFwAAMJZZ39/954ujG50zpnMGwEAoLsQRjoho3WoZmNZlaV1AADQGxFGOsE7iXVD2ZfyeEJ+VAsAgB6FMNIJE89IUp/oCFUeatSmvdVWlwMAQK9CGOmE6Ei7po8aKEla89mJn04MAAACQxjppG+MHSSJMAIAQFcjjHTS+WNbekY+3l2tfTX1FlcDAEDvQRjppEF9YzTxjERJ0trP9ltcDQAAvQdhJADeoZo3tlScpCUAAOgswkgAvjlhsCTp7a379GVto8XVAADQOxBGAjDa2VfjBieoqdno75+UW10OAAC9AmEkQFd8ZYgk6cWP9lhcCQAAvQNhJEDfmpQqu01av/NLlR2os7ocAAB6PMJIgAYlxGjayJYn977yb3pHAAA4XYSRU3DZxFRJ0j82uSyuBACAno8wcgqyxzkVYbdp8143QzUAAJwmwsgp6N8nWpnD+kuSVm1mVQ0AAKeDMHKKLh6fIomhGgAAThdh5BTlnN0SRj4qq5KrmmfVAABwqggjp8iZEKNJaUmSpP/3Oc+qAQDgVBFGTsO0EQMkSe9tP2BxJQAA9FyEkdPgvd/Ie9srZYyxuBoAAHomwshpmDy0n6Ij7apwN2j7/lqrywEAoEcijJyGmKgITT6znySpZHulxdUAANAzEUZO07SRzBsBAOB0EEZOU9aIlnkjJf85II+HeSMAAASKMHKaJp6RqOhIu6rqmlR2kFvDAwAQKMLIaYqKsOuswQmSpI/3VFtcDQAAPQ9hpAtMHJIoSdpEGAEAIGCEkS4woTWMfLy7ytpCAADogQgjXWDCGS1hZPMeN5NYAQAIEGGkC4waFC9HpF01DUe04wA3PwMAIBCEkS4QGWHXuNSWSayfMG8EAICAEEa6iHfeyCe7CSMAAASCMNJFfGGEnhEAAAJCGOki3nuNbK2o4Qm+AAAEgDDSRUYOipfdJn1Z16T9NQ1WlwMAQI9BGOkiMVERSk/uI0kqraixuBoAAHqOUwojS5YsUXp6umJiYpSZmal169Z12PaFF17QlClTlJSUpD59+igjI0NPP/30KRccysY4+0qSSl2EEQAAOivgMLJixQoVFBRo4cKF2rBhgyZNmqScnBzt27ev3fb9+/fXXXfdpZKSEn388cfKz89Xfn6+Xn/99dMuPtSMJowAABCwgMPIokWLNG/ePOXn52vcuHFaunSp4uLitGzZsnbbn3/++fr2t7+ts846SyNGjNDNN9+siRMn6t133z3t4kPN2JTWMMIwDQAAnRZQGGlsbNT69euVnZ199AR2u7Kzs1VSUnLS440xKi4uVmlpqWbMmNFhu4aGBrndbr+tJxjdGka2VtRwW3gAADopoDBSWVmp5uZmOZ1Ov/1Op1Mul6vD46qrqxUfH6/o6GjNmjVLjz76qC688MIO2xcVFSkxMdG3paWlBVKmZdIH9FF0pF31TR6VHayzuhwAAHqEoKym6du3rzZu3KgPPvhA999/vwoKCrR27doO2xcWFqq6utq37dq1KxhlnrYIu02jBsVLYqgGAIDOigykcXJysiIiIlRRUeG3v6KiQikpKR0eZ7fbNXLkSElSRkaGPv30UxUVFen8889vt73D4ZDD4QiktJAxJqWvNu9167PyGuWc3fE1AQAALQLqGYmOjtbkyZNVXFzs2+fxeFRcXKysrKxOn8fj8aihoXfeGGxc651Yt5RzW3gAADojoJ4RSSooKNDcuXM1ZcoUTZ06VYsXL1Ztba3y8/MlSXl5eRoyZIiKiooktcz/mDJlikaMGKGGhga99tprevrpp/X73/++az9JiPA+vXfz3p4x6RYAAKsFHEZyc3O1f/9+LViwQC6XSxkZGVq1apVvUmtZWZns9qMdLrW1tfrhD3+o3bt3KzY2VmPHjtUzzzyj3NzcrvsUIeTs1JYH5u3+8rCq6hqVFBdtcUUAAIQ2m+kBT3Vzu91KTExUdXW1EhISrC7npGb86i2VHazTX67P1LSRyVaXAwCAJTr7+5tn03SDs31DNcwbAQDgZAgj3WD8kJahmk17mDcCAMDJEEa6wTh6RgAA6DTCSDcY3zqJ9T+VtaptOGJxNQAAhDbCSDcY2NchZ4JDxkhbyhmqAQDgRAgj3WTiGUmSpI1lVZbWAQBAqCOMdJPJQ/tJkj7cedDiSgAACG2EkW4ypTWMrN/5pXrArVwAALAMYaSbjB+SqOgIuyoPNWrngTqrywEAIGQRRrpJTFSExg9pWeK7fueXFlcDAEDoIox0oynp/SVJHxJGAADoEGGkG33lTO+8ESaxAgDQEcJIN/KuqNlacUg19U0WVwMAQGgijHQj783PpJZAAgAA2iKMdLPRzr6SpM8raiyuBACA0EQY6WajBrWEEXpGAABoH2Gkm412xkuSPt9HzwgAAO0hjHSzUU5vzwhhBACA9hBGutmo1p6RCneDqg+zogYAgOMRRrpZQkyUBifGSGISKwAA7SGMBMHRoRomsQIAcDzCSBCMaR2qYd4IAABtEUaCwNszwooaAADaIowEwchBLT0j2/fVWlwJAAChhzASBMMG9JEkudz1OtzYbHE1AACEFsJIEPTrE63E2ChJ0s6D9I4AAHAswkiQpA+IkyTtqKyzuBIAAEILYSRIhrYO1ew8QM8IAADHIowESXpySxjZQRgBAMAPYSRIGKYBAKB9hJEgoWcEAID2EUaCJL11zkh5db3qm1jeCwCAF2EkSPrFRalvTKQkqewgQzUAAHgRRoLEZrNpWOtQzReVDNUAAOBFGAkilvcCANAWYSSIfCtqDjBMAwCAF2EkiM7oFytJ2lt12OJKAAAIHYSRIBqcSBgBAOB4hJEgSk1qCSPlVfUWVwIAQOg4pTCyZMkSpaenKyYmRpmZmVq3bl2HbZ944glNnz5d/fr1U79+/ZSdnX3C9r1ZalKMJKmm4Yjc9U0WVwMAQGgIOIysWLFCBQUFWrhwoTZs2KBJkyYpJydH+/bta7f92rVrdeWVV+qtt95SSUmJ0tLSdNFFF2nPnj2nXXxPExcdqaS4KEn0jgAA4GUzxphADsjMzNS5556rxx57TJLk8XiUlpamH/3oR7rjjjtOenxzc7P69eunxx57THl5eZ16T7fbrcTERFVXVyshISGQckPOJb/5f/q03K0/5Z+rr48ZZHU5AAB0m87+/g6oZ6SxsVHr169Xdnb20RPY7crOzlZJSUmnzlFXV6empib179+/wzYNDQ1yu91+W28xpHWohkmsAAC0CCiMVFZWqrm5WU6n02+/0+mUy+Xq1Dluv/12paam+gWa4xUVFSkxMdG3paWlBVJmSGMSKwAA/oK6muaBBx7Q8uXL9eKLLyomJqbDdoWFhaqurvZtu3btCmKV3YvlvQAA+IsMpHFycrIiIiJUUVHht7+iokIpKSknPPbhhx/WAw88oDfffFMTJ048YVuHwyGHwxFIaT2Gd0XN3mrCCAAAUoA9I9HR0Zo8ebKKi4t9+zwej4qLi5WVldXhcb/61a/0i1/8QqtWrdKUKVNOvdpewDtMs5dhGgAAJAXYMyJJBQUFmjt3rqZMmaKpU6dq8eLFqq2tVX5+viQpLy9PQ4YMUVFRkSTpwQcf1IIFC/Tss88qPT3dN7ckPj5e8fHxXfhRegZvGHFV18vjMbLbbRZXBACAtQIOI7m5udq/f78WLFggl8uljIwMrVq1yjeptaysTHb70Q6X3//+92psbNR3v/tdv/MsXLhQd9999+lV3wM5+zpkt0mNzR5V1jZoUN+O584AABAOAr7PiBV6031GJCmrqFjl1fV6ef40TUpLsrocAAC6RbfcZwRdY3Ai9xoBAMCLMGIBZ0JLGNl/qMHiSgAAsB5hxAID4qMlSZWHGi2uBAAA6xFGLNC/T8s9VA7W0jMCAABhxALJrT0jB+gZAQCAMGKF/n1aw0gtYQQAAMKIBQa0DtMcYAIrAACEESt4J7AepGcEAADCiBUGtA7TfFnXpCPNHourAQDAWoQRCyTFRcvW+kiaL+uarC0GAACLEUYsEGG3qX+cdxIr80YAAOGNMGIR74qagyzvBQCEOcKIRXx3YWUSKwAgzBFGLOJd3nuQ5b0AgDBHGLEINz4DAKAFYcQi3mEawggAINwRRizivdcId2EFAIQ7wohFBsR7n9xLzwgAILwRRizimzPC0l4AQJgjjFgkmTkjAABIIoxYpn/r0t7qw01q4vk0AIAwRhixSFJslOze59PQOwIACGOEEYvY7TbfvJFK5o0AAMIYYcRCvruw0jMCAAhjhBELHb0LK/caAQCEL8KIhXx3YWWYBgAQxggjFhpAzwgAAIQRK3EXVgAACCOWYjUNAACEEUt578JKzwgAIJwRRizkvQsrT+4FAIQzwoiFBvB8GgAACCNW8q6mqak/ooYjzRZXAwCANQgjFkqIiVJk6wNqvqxtsrgaAACsQRixkN1uUz/fihrmjQAAwhNhxGLeoRpW1AAAwhVhxGJHJ7HSMwIACE+EEYsN8C3vpWcEABCeTimMLFmyROnp6YqJiVFmZqbWrVvXYdvNmzfrO9/5jtLT02Wz2bR48eJTrbVXOvrkXsIIACA8BRxGVqxYoYKCAi1cuFAbNmzQpEmTlJOTo3379rXbvq6uTsOHD9cDDzyglJSU0y64t/HdhZWeEQBAmAo4jCxatEjz5s1Tfn6+xo0bp6VLlyouLk7Lli1rt/25556rhx56SHPmzJHD4Tjtgnsb311YmTMCAAhTAYWRxsZGrV+/XtnZ2UdPYLcrOztbJSUlXVZUQ0OD3G6339ZbcRdWAEC4CyiMVFZWqrm5WU6n02+/0+mUy+XqsqKKioqUmJjo29LS0rrs3KHGu7SXCawAgHAVkqtpCgsLVV1d7dt27dpldUndZmDflmGafTX1MsZYXA0AAMEXGUjj5ORkRUREqKKiwm9/RUVFl05OdTgcYTO/xJkQI0mqb/LIffiIEuOiLK4IAIDgCqhnJDo6WpMnT1ZxcbFvn8fjUXFxsbKysrq8uHAQExWhfq0BpNx92OJqAAAIvoB6RiSpoKBAc+fO1ZQpUzR16lQtXrxYtbW1ys/PlyTl5eVpyJAhKioqktQy6XXLli2+v+/Zs0cbN25UfHy8Ro4c2YUfpedyJsToy7omuarrNTYlwepyAAAIqoDDSG5urvbv368FCxbI5XIpIyNDq1at8k1qLSsrk91+tMNl7969Ouecc3xfP/zww3r44Yc1c+ZMrV279vQ/QS8wODFGn7lq5Kqut7oUAACCLuAwIkk33XSTbrrppnZfOz5gpKenMzHzJFISW+aNuNyEEQBA+AnJ1TThJiUhVpLoGQEAhCXCSAhISWxZOUTPCAAgHBFGQkBKIj0jAIDwRRgJASkJzBkBAIQvwkgI8E5graprUn1Ts8XVAAAQXISREJAQE6m46AhJDNUAAMIPYSQE2Gw231BNOWEEABBmCCMhwjtUU8G8EQBAmCGMhAh6RgAA4YowEiLoGQEAhCvCSIgY3BpGdh2ss7gSAACCizASIkY7+0qSPnPVWFwJAADBRRgJEWelJkiS9lQdVlVdo8XVAAAQPISREJEQE6Uz+8dJkraUuy2uBgCA4CGMhJBxg1t6R7bsJYwAAMIHYSSEjEsljAAAwg9hJIT4ekYYpgEAhBHCSAjx9oxs23eIB+YBAMIGYSSEDE6MUb+4KB3xGG3bd8jqcgAACArCSAix2Wy+3pFP9lRbXA0AAMFBGAkxk4f2lyStLd1ncSUAAAQHYSTEXDTOKUl6Z2sl80YAAGGBMBJizk5NUGpijA43NevdzyutLgcAgG5HGAkxNptNF52dIkl6Y4vL4moAAOh+hJEQ5B2qKf50n5o9xuJqAADoXoSREHTusP5KjI3SgdpGrfmMiawAgN6NMBKCoiLs+n7mmZKkR1ZvlTH0jgAAei/CSIi6Yfpw9YmO0JZyt17fXGF1OQAAdBvCSIjq1yda+dOGSZJ+/UYpy3wBAL0WYSSEXT99mPrFRenzfYd0z6ubrS4HAIBuQRgJYUlx0frNnHNks0l/XbdLz6/fbXVJAAB0OcJIiJsxeqAKskdLkn7xty2qrmuyuCIAALoWYaQHuPH8ERrtjFf14SY9uuZzq8sBAKBLEUZ6gMgIu+6aNU6S9OeSHdp5oNbiigAA6DqEkR5i5uiBmjF6oJqajR5ZvdXqcgAA6DKEkR7kf3LGSJJe+fde/Wf/IYurAQCgaxBGepDxQxKVfdYgeYz02JptVpcDAECXIIz0MDdf0LKy5qWNe/TaJ+UWVwMAwOkjjPQwE85I1KUTB8tjpB/+ZYN+9NePtGpTuWrqWfILAOiZTimMLFmyROnp6YqJiVFmZqbWrVt3wvYrV67U2LFjFRMTowkTJui11147pWLR4pHcDN14/ghJ0qv/3qsfPLNB59y7Wv/1eIn+8v5OuQkmAIAexGYCfCTsihUrlJeXp6VLlyozM1OLFy/WypUrVVpaqkGDBrVp/95772nGjBkqKirSpZdeqmeffVYPPvigNmzYoPHjx3fqPd1utxITE1VdXa2EhIRAyu3VNpR9qVc27tXbW/fri8qjy30j7DYNTozRGf1ildYvTgP7OtQvLlpJcVFKiotWTJRdMVERiomM8P3d4f0z0q7oCLtsNpuFnwwA0Bt09vd3wGEkMzNT5557rh577DFJksfjUVpamn70ox/pjjvuaNM+NzdXtbW1+tvf/ubb99WvflUZGRlaunRpu+/R0NCghoYGvw+TlpZGGDmBnQdq9cbmCq34cJe27Tv9lTaRdpvsdpsi7TZFtG6RdpvsttZ9ETZF2I6+FmG3K8Iu2WST3SbJZlPrH7JJsttsrX9v2eG3r3V/y9/9j7PZWs/nfb31Nb/zHevEX7Ybstq2Cewcbc7Y5vjj2p/0/Cc+vt02JyniZO8ZKkIxA7d3/UNBaF6r0MT/XHXOdecNU1r/uC49Z2fDSGQgJ21sbNT69etVWFjo22e325Wdna2SkpJ2jykpKVFBQYHfvpycHL300ksdvk9RUZHuueeeQEoLe0MH9NG8GcN1/fRhqnA3aPeXddr95WHtOlinA7WN+rKuUV/WNan6cJMamppV39Ss+iaP6o80q6H1z2Nj6RGPkTxGjdZ9JABAEH0rI7XLw0hnBRRGKisr1dzcLKfT6bff6XTqs88+a/cYl8vVbnuXy9Xh+xQWFvoFGG/PCE7OZrMpJTFGKYkxmpLe+eOMMWps9qi+yaPGIx55jNERj1Fzs1GzMWr2eNTskY54PGr2mDbbEU9LOxnJyMjjkUzreVv+PO7vMjJG8rQmIP99R9v6zmf82/he9/sMbT+T39cna9/ONen4eh1/rDnJ66d3/InqOt33CnWB9d1ar0eV28Mubs+qtsddXqUkxFj23gGFkWBxOBxyOBxWlxFWbDabHJERckRGWF0KACDMBLSaJjk5WREREaqoqPDbX1FRoZSUlHaPSUlJCag9AAAILwGFkejoaE2ePFnFxcW+fR6PR8XFxcrKymr3mKysLL/2krR69eoO2wMAgPAS8DBNQUGB5s6dqylTpmjq1KlavHixamtrlZ+fL0nKy8vTkCFDVFRUJEm6+eabNXPmTP3617/WrFmztHz5cn344Yf6wx/+0LWfBAAA9EgBh5Hc3Fzt379fCxYskMvlUkZGhlatWuWbpFpWVia7/WiHy9e+9jU9++yz+tnPfqY777xTo0aN0ksvvdTpe4wAAIDeLeD7jFiBm54BANDzdPb3N8+mAQAAliKMAAAASxFGAACApQgjAADAUoQRAABgKcIIAACwFGEEAABYijACAAAsFZJP7T2e975sbrfb4koAAEBneX9vn+z+qj0ijNTU1EiS0tLSLK4EAAAEqqamRomJiR2+3iNuB+/xeLR371717dtXNputy87rdruVlpamXbt2cZv5bsI17l5c3+7HNe5eXN/uZfX1NcaopqZGqampfs+tO16P6Bmx2+0644wzuu38CQkJ/EfQzbjG3Yvr2/24xt2L69u9rLy+J+oR8WICKwAAsBRhBAAAWCqsw4jD4dDChQvlcDisLqXX4hp3L65v9+Mady+ub/fqKde3R0xgBQAAvVdY94wAAADrEUYAAIClCCMAAMBShBEAAGApwggAALBUWIeRJUuWKD09XTExMcrMzNS6deusLqlHuvvuu2Wz2fy2sWPH+l6vr6/X/PnzNWDAAMXHx+s73/mOKioqLKw4tL3zzju67LLLlJqaKpvNppdeesnvdWOMFixYoMGDBys2NlbZ2dn6/PPP/docPHhQV111lRISEpSUlKTrrrtOhw4dCuKnCG0nu8bXXnttm+/piy++2K8N17hjRUVFOvfcc9W3b18NGjRIs2fPVmlpqV+bzvxcKCsr06xZsxQXF6dBgwbptttu05EjR4L5UUJSZ67v+eef3+Z7+Ac/+IFfm1C6vmEbRlasWKGCggItXLhQGzZs0KRJk5STk6N9+/ZZXVqPdPbZZ6u8vNy3vfvuu77Xbr31Vr366qtauXKl3n77be3du1dXXHGFhdWGttraWk2aNElLlixp9/Vf/epX+u1vf6ulS5fq/fffV58+fZSTk6P6+npfm6uuukqbN2/W6tWr9be//U3vvPOObrjhhmB9hJB3smssSRdffLHf9/Rf//pXv9e5xh17++23NX/+fP3rX//S6tWr1dTUpIsuuki1tbW+Nif7udDc3KxZs2apsbFR7733nv785z/rqaee0oIFC6z4SCGlM9dXkubNm+f3PfyrX/3K91rIXV8TpqZOnWrmz5/v+7q5udmkpqaaoqIiC6vqmRYuXGgmTZrU7mtVVVUmKirKrFy50rfv008/NZJMSUlJkCrsuSSZF1980fe1x+MxKSkp5qGHHvLtq6qqMg6Hw/z1r381xhizZcsWI8l88MEHvjb/+Mc/jM1mM3v27Ala7T3F8dfYGGPmzp1rLr/88g6P4RoHZt++fUaSefvtt40xnfu58Nprrxm73W5cLpevze9//3uTkJBgGhoagvsBQtzx19cYY2bOnGluvvnmDo8Jtesblj0jjY2NWr9+vbKzs3377Ha7srOzVVJSYmFlPdfnn3+u1NRUDR8+XFdddZXKysokSevXr1dTU5PftR47dqzOPPNMrvUp+OKLL+RyufyuZ2JiojIzM33Xs6SkRElJSZoyZYqvTXZ2tux2u95///2g19xTrV27VoMGDdKYMWN044036sCBA77XuMaBqa6uliT1799fUud+LpSUlGjChAlyOp2+Njk5OXK73dq8eXMQqw99x19fr7/85S9KTk7W+PHjVVhYqLq6Ot9roXZ9e8RTe7taZWWlmpub/f4RJMnpdOqzzz6zqKqeKzMzU0899ZTGjBmj8vJy3XPPPZo+fbo2bdokl8ul6OhoJSUl+R3jdDrlcrmsKbgH816z9r53va+5XC4NGjTI7/XIyEj179+fa95JF198sa644goNGzZM27dv15133qlLLrlEJSUlioiI4BoHwOPx6JZbbtG0adM0fvx4SerUzwWXy9Xu97n3NbRo7/pK0ve//30NHTpUqamp+vjjj3X77bertLRUL7zwgqTQu75hGUbQtS655BLf3ydOnKjMzEwNHTpUzz33nGJjYy2sDDg1c+bM8f19woQJmjhxokaMGKG1a9fqggsusLCynmf+/PnatGmT3zwydJ2Oru+x85cmTJigwYMH64ILLtD27ds1YsSIYJd5UmE5TJOcnKyIiIg2M7crKiqUkpJiUVW9R1JSkkaPHq1t27YpJSVFjY2Nqqqq8mvDtT413mt2ou/dlJSUNhOxjxw5ooMHD3LNT9Hw4cOVnJysbdu2SeIad9ZNN92kv/3tb3rrrbd0xhln+PZ35udCSkpKu9/n3tfQ8fVtT2ZmpiT5fQ+H0vUNyzASHR2tyZMnq7i42LfP4/GouLhYWVlZFlbWOxw6dEjbt2/X4MGDNXnyZEVFRfld69LSUpWVlXGtT8GwYcOUkpLidz3dbrfef/993/XMyspSVVWV1q9f72uzZs0aeTwe3w8kBGb37t06cOCABg8eLIlrfDLGGN1000168cUXtWbNGg0bNszv9c78XMjKytInn3ziF/pWr16thIQEjRs3LjgfJESd7Pq2Z+PGjZLk9z0cUtc36FNmQ8Ty5cuNw+EwTz31lNmyZYu54YYbTFJSkt/MYnTOT37yE7N27VrzxRdfmH/+858mOzvbJCcnm3379hljjPnBD35gzjzzTLNmzRrz4YcfmqysLJOVlWVx1aGrpqbGfPTRR+ajjz4yksyiRYvMRx99ZHbu3GmMMeaBBx4wSUlJ5uWXXzYff/yxufzyy82wYcPM4cOHfee4+OKLzTnnnGPef/998+6775pRo0aZK6+80qqPFHJOdI1ramrMT3/6U1NSUmK++OIL8+abb5qvfOUrZtSoUaa+vt53Dq5xx2688UaTmJho1q5da8rLy31bXV2dr83Jfi4cOXLEjB8/3lx00UVm48aNZtWqVWbgwIGmsLDQio8UUk52fbdt22buvfde8+GHH5ovvvjCvPzyy2b48OFmxowZvnOE2vUN2zBijDGPPvqoOfPMM010dLSZOnWq+de//mV1ST1Sbm6uGTx4sImOjjZDhgwxubm5Ztu2bb7XDx8+bH74wx+afv36mbi4OPPtb3/blJeXW1hxaHvrrbeMpDbb3LlzjTEty3t//vOfG6fTaRwOh7ngggtMaWmp3zkOHDhgrrzyShMfH28SEhJMfn6+qampseDThKYTXeO6ujpz0UUXmYEDB5qoqCgzdOhQM2/evDb/o8I17lh711aS+dOf/uRr05mfCzt27DCXXHKJiY2NNcnJyeYnP/mJaWpqCvKnCT0nu75lZWVmxowZpn///sbhcJiRI0ea2267zVRXV/udJ5Sur80YY4LXDwMAAOAvLOeMAACA0EEYAQAAliKMAAAASxFGAACApQgjAADAUoQRAABgKcIIAACwFGEEAABYijACAAAsRRgBAACWIowAAABL/X+1voruZdvD+wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_parameter_masks=dict()\n",
    "for name,parameter in DLGN_init.named_parameters():\n",
    "    if name[:5]==\"value_\"[:5]:\n",
    "        train_parameter_masks[name]=torch.ones_like(parameter) # Updating all value network layers\n",
    "    if name[:5]==\"gating_\"[:5]:\n",
    "        train_parameter_masks[name]=torch.ones_like(parameter)\n",
    "    train_parameter_masks[name].to(device)\n",
    "\n",
    "set_torchseed(5000)\n",
    "train_losses, DLGN_obj_final, DLGN_obj_store = train_dlgn(train_data_curr=train_data,\n",
    "                                            vali_data_curr=vali_data,\n",
    "                                            test_data_curr=test_data,\n",
    "                                            train_labels_curr=train_data_labels,\n",
    "                                            vali_labels_curr=vali_data_labels,\n",
    "                                            test_labels_curr=test_data_labels,\n",
    "                                            DLGN_obj=deepcopy(DLGN_init),\n",
    "                                            parameter_mask=train_parameter_masks)\n",
    "torch.cuda.empty_cache() \n",
    "\n",
    "# print(DLGN_obj_store[-1].beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('outputs'):\n",
    "    os.mkdir('outputs')\n",
    "# print(len(DLGN_obj_store))\n",
    "# print(\"Hi\")\n",
    "device=torch.device('cpu')\n",
    "train_outputs_values, train_outputs_gate_scores =DLGN_obj_final(torch.Tensor(train_data).to(device))\n",
    "train_preds = train_outputs_values[-1]\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "outputs = torch.cat((-1*train_preds,train_preds), dim=1)\n",
    "targets = torch.tensor(train_data_labels, dtype=torch.int64)\n",
    "train_loss = criterion(outputs, targets)\n",
    "train_preds = train_preds.detach().numpy()\n",
    "filename = 'outputs/'+filename_suffix+'.txt'\n",
    "original_stdout = sys.stdout\n",
    "with open(filename,'w') as f:\n",
    "    sys.stdout = f\n",
    "    print(\"Setup:\")\n",
    "    print(\"Num neurons : \", DLGN_obj_final.num_nodes)\n",
    "    print(\" Beta :\", DLGN_obj_final.beta)\n",
    "    print(\" lr :\", lr)\n",
    "    print(\"=======================\")\n",
    "    print(train_losses)\n",
    "    print(\"==========Best validated model=============\")\n",
    "    print(\"Train error=\",np.sum(train_data_labels != (np.sign(train_preds[:,0])+1)//2 ))\n",
    "    print(\"Train loss = \", train_loss)\n",
    "    print(\"Num_train_data=\",len(train_data_labels))\n",
    "    sys.stdout = original_stdout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_outputs_values, test_outputs_gate_scores =DLGN_obj_final(torch.Tensor(test_data))\n",
    "test_preds = test_outputs_values[-1]\n",
    "test_preds = test_preds.detach().numpy()\n",
    "filename = 'outputs/'+filename_suffix+'.txt'\n",
    "original_stdout = sys.stdout\n",
    "with open(filename,'a') as f:\n",
    "    sys.stdout = f\n",
    "    print(\"Test error=\",np.sum(test_data_labels != (np.sign(test_preds[:,0])+1)//2 ))\n",
    "    print(\"Num_test_data=\",len(test_data_labels))\n",
    "    sys.stdout = original_stdout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learned feature statistics of best validation model\n",
    "\n",
    "w_list = np.concatenate((w_list_old,-w_list_old),axis=0)\n",
    "\n",
    "effective_weights, effective_biases = DLGN_obj_store[0].return_gating_functions()\n",
    "wts_list_init=[]\n",
    "for layer in range(0,len(effective_weights)):\n",
    "    wts =  np.array(effective_weights[layer].data.detach().numpy())\n",
    "    wts /= np.linalg.norm(wts, axis=1)[:,None]\n",
    "    wts_list_init.append(wts)\n",
    "wts_list_init = np.concatenate(wts_list_init)\n",
    "\n",
    "\n",
    "effective_weights, effective_biases = DLGN_obj_final.return_gating_functions()\n",
    "\n",
    "wts_list=[]\n",
    "for layer in range(len(effective_weights)):\n",
    "    wts =  np.array(effective_weights[layer].data.detach().numpy())\n",
    "    wts /= np.linalg.norm(wts, axis=1)[:,None]\n",
    "    wts_list.append(wts)\n",
    "wts_list = np.concatenate(wts_list)\n",
    "\n",
    "pd0 =  pairwise_distances(w_list,wts_list_init)\n",
    "pd1 =  pairwise_distances(w_list,wts_list)\n",
    "\n",
    "\n",
    "filename = 'outputs/'+filename_suffix+'.txt'\n",
    "original_stdout = sys.stdout\n",
    "with open(filename,'a') as f:\n",
    "    sys.stdout = f\n",
    "    print(\"Shape of decision tree node hyperplanes \", w_list.shape)\n",
    "    print(\"Shape of all halfspace directions of DLGN\", wts_list.shape)\n",
    "    print(\"Distance of closest init DLGN halfspace to each labelling func hyperplane \\n\", pd0.min(axis=1)[:len(w_list_old)])\n",
    "    print(pd0.min(axis=1)[len(w_list_old):])\n",
    "    print(\"Distance of closest lrnd DLGN halfspace to each labelling func hyperplane \\n\", pd1.min(axis=1)[:len(w_list_old)])\n",
    "    print(pd1.min(axis=1)[len(w_list_old):])\n",
    "    print(\"Number of halfspaces within distance 0.8 of the Dtree hyperplanes \\n\", np.sum(pd1<0.8, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd1<0.8, axis=1)[len(w_list_old):])\n",
    "    print(\"Number of halfspaces within distance 0.6 of the Dtree hyperplanes \\n\", np.sum(pd1<0.6, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd1<0.6, axis=1)[len(w_list_old):])\n",
    "    print(\"Number of halfspaces within distance 0.4 of the Dtree hyperplanes \\n\", np.sum(pd1<0.4, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd1<0.4, axis=1)[len(w_list_old):])\n",
    "    print(\"Number of halfspaces within distance 0.3 of the Dtree hyperplanes \\n\", np.sum(pd1<0.3, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd1<0.3, axis=1)[len(w_list_old):])\n",
    "    print(\"Number of halfspaces within distance 0.2 of the Dtree hyperplanes \\n\", np.sum(pd1<0.2, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd1<0.2, axis=1)[len(w_list_old):])\n",
    "    print(\"Number of halfspaces within distance 0.1 of the Dtree hyperplanes \\n\", np.sum(pd1<0.1, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd1<0.1, axis=1)[len(w_list_old):])\n",
    "    print(\"=========================================\")\n",
    "    sys.stdout = original_stdout\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learned feature statistics of init model\n",
    "epoch_index=0\n",
    "effective_weights, effective_biases = DLGN_obj_store[epoch_index].return_gating_functions()\n",
    "wts_list=[]\n",
    "for layer in range(len(effective_weights)):\n",
    "    wts =  np.array(effective_weights[layer].data.detach().numpy())\n",
    "    wts /= np.linalg.norm(wts, axis=1)[:,None]\n",
    "    wts_list.append(wts)\n",
    "wts_list = np.concatenate(wts_list)\n",
    "pd0 =  pairwise_distances(w_list,wts_list_init)\n",
    "pd1 =  pairwise_distances(w_list,wts_list)\n",
    "pd_w_list = pairwise_distances(w_list, w_list)\n",
    "\n",
    "\n",
    "filename = 'outputs/'+filename_suffix+'.txt'\n",
    "original_stdout = sys.stdout\n",
    "with open(filename,'a') as f:\n",
    "    sys.stdout = f\n",
    "    print(\"===================================\")\n",
    "    print(\"Initial epoch\")\n",
    "    print(epoch_index)\n",
    "    print(\"===================================\")\n",
    "    train_outputs_values, train_outputs_gate_scores =DLGN_obj_store[epoch_index](torch.Tensor(train_data).to(device))\n",
    "    train_preds = train_outputs_values[-1]\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    outputs = torch.cat((-1*train_preds,train_preds), dim=1)\n",
    "    targets = torch.tensor(train_data_labels, dtype=torch.int64)\n",
    "    train_loss = criterion(outputs, targets)\n",
    "    train_preds = train_preds.detach().numpy()\n",
    "    test_outputs_values, test_outputs_gate_scores =DLGN_obj_store[epoch_index](torch.Tensor(test_data))\n",
    "    test_preds = test_outputs_values[-1]\n",
    "    test_preds = test_preds.detach().numpy()\n",
    "    print(\"Train error=\",np.sum(train_data_labels != (np.sign(train_preds[:,0])+1)//2 ))\n",
    "    print(\"Num_train_data=\",len(train_data_labels))\n",
    "    print(\"Train loss=\",train_loss.detach())\n",
    "    print(\"Test error=\",np.sum(test_data_labels != (np.sign(test_preds[:,0])+1)//2 ))\n",
    "    print(\"Num_test_data=\",len(test_data_labels))\n",
    "    print(\"===================================\")\n",
    "    print(\"Shape of decision tree node hyperplanes \", w_list.shape)\n",
    "    print(\"Shape of all halfspace directions of DLGN\", wts_list.shape)\n",
    "    print(\"Distance of closest init DLGN halfspace to each labelling func hyperplane \\n\", pd0.min(axis=1)[:len(w_list_old)])\n",
    "    print(pd0.min(axis=1)[len(w_list_old):])\n",
    "    print(\"Distance of closest lrnd DLGN halfspace to each labelling func hyperplane \\n\", pd1.min(axis=1)[:len(w_list_old)])\n",
    "    print(pd1.min(axis=1)[len(w_list_old):])\n",
    "    print(\"Number of halfspaces within distance 0.8 of the Dtree hyperplanes \\n\", np.sum(pd1<0.8, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd1<0.8, axis=1)[len(w_list_old):])\n",
    "    print(\"Number of halfspaces within distance 0.6 of the Dtree hyperplanes \\n\", np.sum(pd1<0.6, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd1<0.6, axis=1)[len(w_list_old):])\n",
    "    print(\"Number of halfspaces within distance 0.4 of the Dtree hyperplanes \\n\", np.sum(pd1<0.4, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd1<0.4, axis=1)[len(w_list_old):])\n",
    "    print(\"Number of halfspaces within distance 0.3 of the Dtree hyperplanes \\n\", np.sum(pd1<0.3, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd1<0.3, axis=1)[len(w_list_old):])\n",
    "    print(\"Number of halfspaces within distance 0.2 of the Dtree hyperplanes \\n\", np.sum(pd1<0.2, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd1<0.2, axis=1)[len(w_list_old):])\n",
    "    print(\"Number of halfspaces within distance 0.1 of the Dtree hyperplanes \\n\", np.sum(pd1<0.1, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd1<0.1, axis=1)[len(w_list_old):])\n",
    "    print(\"=========================================\")\n",
    "    sys.stdout = original_stdout    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learned feature statistics of last iteration model\n",
    "epoch_index=len(DLGN_obj_store)-1\n",
    "effective_weights, effective_biases = DLGN_obj_store[epoch_index].return_gating_functions()\n",
    "wts_list=[]\n",
    "for layer in range(len(effective_weights)):\n",
    "    wts =  np.array(effective_weights[layer].data.detach().numpy())\n",
    "    wts /= np.linalg.norm(wts, axis=1)[:,None]\n",
    "    wts_list.append(wts)\n",
    "wts_list = np.concatenate(wts_list)\n",
    "\n",
    "pd0 =  pairwise_distances(w_list,wts_list_init)\n",
    "pd1 =  pairwise_distances(w_list,wts_list)\n",
    "pd_w_list = pairwise_distances(w_list, w_list)\n",
    "w_list_random = np.random.standard_normal(w_list.shape)\n",
    "w_list_random /= np.linalg.norm(w_list_random, axis=1)[:,None]\n",
    "\n",
    "pd4 = pairwise_distances(w_list_random,wts_list)\n",
    "\n",
    "\n",
    "filename = 'outputs/'+filename_suffix+'.txt'\n",
    "original_stdout = sys.stdout\n",
    "with open(filename,'a') as f:\n",
    "    sys.stdout = f\n",
    "    print(\"===================================\")\n",
    "    print(\"last epoch: Training loss = \", train_losses[-1])\n",
    "    print(epoch_index)\n",
    "    print(saved_epochs[epoch_index])\n",
    "    print(\"===================================\")\n",
    "    train_outputs_values, train_outputs_gate_scores =DLGN_obj_store[epoch_index](torch.Tensor(train_data).to(device))\n",
    "    train_preds = train_outputs_values[-1]\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    outputs = torch.cat((-1*train_preds,train_preds), dim=1)\n",
    "    targets = torch.tensor(train_data_labels, dtype=torch.int64)\n",
    "    train_loss = criterion(outputs, targets)\n",
    "    train_preds = train_preds.detach().numpy()\n",
    "    test_outputs_values, test_outputs_gate_scores =DLGN_obj_store[epoch_index](torch.Tensor(test_data))\n",
    "    test_preds = test_outputs_values[-1]\n",
    "    test_preds = test_preds.detach().numpy()\n",
    "    print(\"Train error=\",np.sum(train_data_labels != (np.sign(train_preds[:,0])+1)//2 ))\n",
    "    print(\"Num_train_data=\",len(train_data_labels))\n",
    "    print(\"Train loss=\",train_loss.detach())\n",
    "    print(\"Test error=\",np.sum(test_data_labels != (np.sign(test_preds[:,0])+1)//2 ))\n",
    "    print(\"Num_test_data=\",len(test_data_labels))\n",
    "    print(\"===================================\")\n",
    "\n",
    "    print(\"Shape of decision tree node hyperplanes \", w_list.shape)\n",
    "    print(\"Shape of all halfspace directions of DLGN\", wts_list.shape)\n",
    "    print(\"Distance of closest init DLGN halfspace to each labelling func hyperplane \\n\", pd0.min(axis=1)[:len(w_list_old)])\n",
    "    print(pd0.min(axis=1)[len(w_list_old):])\n",
    "    print(\"Distance of closest lrnd DLGN halfspace to each labelling func hyperplane \\n\", pd1.min(axis=1)[:len(w_list_old)])\n",
    "    print(pd1.min(axis=1)[len(w_list_old):])\n",
    "    print(\"Number of halfspaces within distance 0.8 of the Dtree hyperplanes \\n\", np.sum(pd1<0.8, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd1<0.8, axis=1)[len(w_list_old):])\n",
    "    print(\"Number of halfspaces within distance 0.6 of the Dtree hyperplanes \\n\", np.sum(pd1<0.6, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd1<0.6, axis=1)[len(w_list_old):])\n",
    "    print(\"Number of halfspaces within distance 0.4 of the Dtree hyperplanes \\n\", np.sum(pd1<0.4, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd1<0.4, axis=1)[len(w_list_old):])\n",
    "    print(\"Number of halfspaces within distance 0.3 of the Dtree hyperplanes \\n\", np.sum(pd1<0.3, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd1<0.3, axis=1)[len(w_list_old):])\n",
    "    print(\"Number of halfspaces within distance 0.2 of the Dtree hyperplanes \\n\", np.sum(pd1<0.2, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd1<0.2, axis=1)[len(w_list_old):])\n",
    "    print(\"Number of halfspaces within distance 0.1 of the Dtree hyperplanes \\n\", np.sum(pd1<0.1, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd1<0.1, axis=1)[len(w_list_old):])\n",
    "\n",
    "\n",
    "    print(\"=========================================\")\n",
    "    print(\"No. of halfspaces within distance 0.8 of a random Dtree hyperplanes \\n\", np.sum(pd4<0.8, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd4<0.8, axis=1)[len(w_list_old):])\n",
    "    print(\"No. of halfspaces within distance 0.6 of a random Dtree hyperplanes \\n\", np.sum(pd4<0.6, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd4<0.6, axis=1)[len(w_list_old):])\n",
    "    print(\"No. of halfspaces within distance 0.4 of a random Dtree hyperplanes \\n\", np.sum(pd4<0.4, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd4<0.4, axis=1)[len(w_list_old):])\n",
    "    print(\"No. of halfspaces within distance 0.3 of a random Dtree hyperplanes \\n\", np.sum(pd4<0.3, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd4<0.3, axis=1)[len(w_list_old):])\n",
    "    print(\"No. of halfspaces within distance 0.2 of a random Dtree hyperplanes \\n\", np.sum(pd4<0.2, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd4<0.2, axis=1)[len(w_list_old):])\n",
    "    print(\"No. of halfspaces within distance 0.1 of a random Dtree hyperplanes \\n\", np.sum(pd4<0.1, axis=1)[:len(w_list_old)])\n",
    "    print(np.sum(pd4<0.1, axis=1)[len(w_list_old):])\n",
    "    sys.stdout = original_stdout    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_utils import train, test\n",
    "from network import Net \n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(input_dim=input_dim, output_dim=2, hidden_dim=1, num_layer=12, num_back_layer=0, dense=True, drop_type='none', net_type='locally_constant', approx='interpolation').to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, nesterov=True)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def get_train_loader(train_data, train_data_labels, batch_size):\n",
    "    # Convert data and labels to PyTorch tensors\n",
    "    train_data_tensor = torch.tensor(train_data, dtype=torch.float32)\n",
    "    train_data_labels_tensor = torch.tensor(train_data_labels, dtype=torch.long)\n",
    "\n",
    "    # Create a TensorDataset from the data and labels tensors\n",
    "    dataset = TensorDataset(train_data_tensor, train_data_labels_tensor)\n",
    "\n",
    "    # Create a DataLoader from the dataset\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return loader\n",
    "train_loader = get_train_loader(train_data, train_data_labels, batch_size=32)\n",
    "valid_loader = get_train_loader(vali_data, vali_data_labels, batch_size=32)\n",
    "test_loader = get_train_loader(test_data, test_data_labels, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47473191210028404 0.770068671560502 0.47368441481886175 0.7640928469919469 0.47384913377834054 0.7770941788925698\n",
      "0.3987438229907047 0.8070092351408951 0.3926134513826068 0.8105163429654192 0.397744808654564 0.8092759110269758\n",
      "0.3931734214708643 0.8200331517878285 0.3875286571226206 0.8195168166745618 0.39319310541464375 0.8187411263606247\n",
      "0.45509998114674177 0.767700686715605 0.45448353910604283 0.7707247749881573 0.4509586978155434 0.7690487458589683\n",
      "0.48221530548464253 0.7354960928250059 0.49266718688704625 0.7314069161534817 0.47727756123942217 0.7368670137245622\n",
      "0.4858717644014207 0.7639119109637699 0.48627265286863497 0.7621980104216012 0.4907412958960368 0.7723615712257453\n",
      "0.4660886662451825 0.751124792801326 0.4720261138742538 0.7498815727143534 0.465786929836896 0.7572172266919073\n",
      "0.4600598260516836 0.7508879943168364 0.46267599361533523 0.7503552818569399 0.4594309601775854 0.7586370089919545\n",
      "0.44731235944516223 0.7833293866919252 0.44321569748141654 0.7835149218379914 0.4428233784758757 0.7946048272598202\n",
      "0.42449523813770246 0.7736206488278475 0.43045528823874224 0.7702510658455708 0.4224067934869422 0.7780407004259347\n",
      "0.41078399149637046 0.7790670139711106 0.41480975736096704 0.7806726669824727 0.40464751072971955 0.7841930903928065\n",
      "0.41711037807658813 0.7774094245796827 0.4206942529375663 0.7783041212695405 0.41065270293123185 0.7818267865593942\n",
      "0.42616601321134356 0.7688846791380535 0.43038600025330603 0.7664613927048792 0.4254479131397341 0.7657359204921912\n",
      "0.4234283629283503 0.7755150367037651 0.4213928677131078 0.777830412126954 0.4195345584329586 0.7742546142924751\n",
      "0.4213098874454557 0.7766990291262136 0.4279099116106273 0.7726196115585031 0.41946755558379273 0.7695220066256507\n",
      "0.4134137521500331 0.7830925882074354 0.4178082634633551 0.7806726669824727 0.40670418976270584 0.7813535257927118\n",
      "0.4109333272288542 0.7911437366800852 0.4141943591401115 0.7887257224064425 0.40148556277365677 0.792238523426408\n",
      "0.42738071223048274 0.7842765806298839 0.42392097429775166 0.7858834675509238 0.41386768372770855 0.7846663511594889\n",
      "0.4426795751484485 0.7840397821453943 0.43842585015669644 0.7839886309805779 0.4267437579052966 0.7827733080927591\n",
      "0.451154580139984 0.7774094245796827 0.4440556835190824 0.7783041212695405 0.4421808632162091 0.7766209181258874\n",
      "0.4547471476199642 0.7766990291262136 0.4461032387658015 0.7783041212695405 0.44389927575529553 0.7766209181258874\n",
      "0.45752254741722 0.7755150367037651 0.44642107207760434 0.777830412126954 0.4433515195422301 0.7756743965925225\n",
      "0.46185518841085177 0.7752782382192754 0.4475100809564414 0.7764092846991947 0.4459100924873036 0.7761476573592049\n",
      "0.463978383599258 0.7743310442813166 0.4481463572358927 0.7749881572714353 0.44437348073232924 0.77520113582584\n",
      "0.4640678135444845 0.774804641250296 0.45262730285377084 0.773567029843676 0.45189852571803363 0.7733080927591103\n",
      "0.4634457135861049 0.774094245796827 0.4579041479662774 0.7721459024159166 0.4528664627773145 0.7733080927591103\n",
      "0.4647575742453725 0.774094245796827 0.45804635521813286 0.7707247749881573 0.4566315936918119 0.7718883104590629\n",
      "0.4685041839523731 0.7731470518588681 0.4586217054423988 0.7697773567029844 0.4574250407019781 0.7709417889256981\n",
      "0.4693520419721267 0.7714894624674402 0.45576194110836027 0.7693036475603979 0.45161822900860105 0.7718883104590629\n",
      "0.472871412181922 0.7703054700449917 0.4632186966448359 0.7683562292752251 0.45122449809814935 0.7728348319924279\n",
      "0.47264704364412574 0.770068671560502 0.4630553106852811 0.7683562292752251 0.45087767132173145 0.7723615712257453\n",
      "0.47188060904125056 0.7703054700449917 0.463079029211553 0.7683562292752251 0.45054377102585297 0.7723615712257453\n",
      "0.47181327541151685 0.770068671560502 0.4628614789781159 0.7683562292752251 0.4501734570239993 0.7728348319924279\n",
      "0.47164541676291183 0.770068671560502 0.4626563400637194 0.7683562292752251 0.4503622081076089 0.7728348319924279\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/sooraj/sem/ugrc/benchmarks/DecisionTree_DLGN_Shared_Aug8.ipynb Cell 26\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sooraj/sem/ugrc/benchmarks/DecisionTree_DLGN_Shared_Aug8.ipynb#X35sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# used for plotting learning curves\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sooraj/sem/ugrc/benchmarks/DecisionTree_DLGN_Shared_Aug8.ipynb#X35sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m train_loss, train_score \u001b[39m=\u001b[39m test(model, device, train_loader, \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/sooraj/sem/ugrc/benchmarks/DecisionTree_DLGN_Shared_Aug8.ipynb#X35sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m valid_loss, valid_score \u001b[39m=\u001b[39m test(model, device, valid_loader, \u001b[39m'\u001b[39;49m\u001b[39mvalid\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sooraj/sem/ugrc/benchmarks/DecisionTree_DLGN_Shared_Aug8.ipynb#X35sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m test_loss, test_score \u001b[39m=\u001b[39m test(model, device, test_loader, \u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sooraj/sem/ugrc/benchmarks/DecisionTree_DLGN_Shared_Aug8.ipynb#X35sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# early stopping version\u001b[39;00m\n",
      "File \u001b[0;32m~/sem/ugrc/benchmarks/train_utils.py:62\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, device, test_loader, test_set_name)\u001b[0m\n\u001b[1;32m     59\u001b[0m tree_x \u001b[39m=\u001b[39m []\n\u001b[1;32m     60\u001b[0m tree_pattern \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 62\u001b[0m \u001b[39mfor\u001b[39;00m data, target \u001b[39min\u001b[39;00m test_loader:\n\u001b[1;32m     63\u001b[0m     dataset_len \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(target)\n\u001b[1;32m     64\u001b[0m     label \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(target)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:264\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    204\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[39m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[39m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[39m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m     \u001b[39mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[39m=\u001b[39;49mdefault_collate_fn_map)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map) \u001b[39mfor\u001b[39;49;00m samples \u001b[39min\u001b[39;49;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mif\u001b[39;00m collate_fn_map \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     \u001b[39mif\u001b[39;00m elem_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 119\u001b[0m         \u001b[39mreturn\u001b[39;00m collate_fn_map[elem_type](batch, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map)\n\u001b[1;32m    121\u001b[0m     \u001b[39mfor\u001b[39;00m collate_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    122\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    160\u001b[0m     storage \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39m_typed_storage()\u001b[39m.\u001b[39m_new_shared(numel, device\u001b[39m=\u001b[39melem\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    161\u001b[0m     out \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mnew(storage)\u001b[39m.\u001b[39mresize_(\u001b[39mlen\u001b[39m(batch), \u001b[39m*\u001b[39m\u001b[39mlist\u001b[39m(elem\u001b[39m.\u001b[39msize()))\n\u001b[0;32m--> 162\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack(batch, \u001b[39m0\u001b[39;49m, out\u001b[39m=\u001b[39;49mout)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_score = 100000\n",
    "for epoch in range(0, 100):\n",
    "        scheduler.step(epoch)\n",
    "\n",
    "        train_approximate_loss = train(model, device, train_loader, optimizer, epoch, 'none',1)\n",
    "        # used for plotting learning curves\n",
    "        train_loss, train_score = test(model, device, train_loader, 'train')\n",
    "        valid_loss, valid_score = test(model, device, valid_loader, 'valid')\n",
    "        test_loss, test_score = test(model, device, test_loader, 'test')\n",
    "        \n",
    "        # early stopping version\n",
    "        if valid_score > best_score:\n",
    "            state = {'model': model.state_dict()}\n",
    "            torch.save(state, \"best_lcn.pt\")\n",
    "            best_score = valid_score\n",
    "\n",
    "        # \"convergent\" version\n",
    "        state = {'model': model.state_dict()}\n",
    "        torch.save(state, \"last_lcn.pt\")\n",
    "        print(train_loss, train_score, valid_loss, valid_score, test_loss, test_score)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "00ad5f1807eee938f7727b558c9158a01118eae9a3a444b82c1137c2e4c2794d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
